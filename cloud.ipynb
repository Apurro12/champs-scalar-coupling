{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fastai import *\n",
    "from fastai.basic_train import *\n",
    "from fastai.basic_data import *\n",
    "from fastai.data_block import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.train import *\n",
    "from fastai.callback import *\n",
    "from fastai.distributed import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(fname, type_index=None):\n",
    "    t  = pd.read_csv(fname)\n",
    "    s  = pd.read_csv('structures.csv')\n",
    "    \n",
    "    has_y = 'scalar_coupling_constant' in t.columns\n",
    "\n",
    "    if has_y:\n",
    "        # atom-atom level\n",
    "        # molecule_name,atom_index_0,atom_index_1,type,fc,sd,pso,dso\n",
    "        scalar_couplings = pd.read_csv('scalar_coupling_contributions.csv') # fc,sd,pso,dso\n",
    "\n",
    "        # atom level\n",
    "        # molecule_name,atom_index,XX,YX,ZX,XY,YY,ZY,XZ,YZ,ZZ\n",
    "        magnetic_shielding = pd.read_csv('magnetic_shielding_tensors.csv')\n",
    "        # molecule_name,atom_index,mulliken_charge\n",
    "        mulliken_charges = pd.read_csv('mulliken_charges.csv')\n",
    "\n",
    "        # molecule level\n",
    "        # molecule_name,X,Y,Z\n",
    "        dipole_moments = pd.read_csv('dipole_moments.csv')\n",
    "        # molecule_name,potential_energy\n",
    "        potential_energy = pd.read_csv('potential_energy.csv')\n",
    "\n",
    "    t['molecule_index'] = pd.factorize(t['molecule_name'])[0] + t['id'].min()\n",
    "    # make sure we use the same indexes in train/test (test needs to provide type_index)\n",
    "    if type_index is not None:\n",
    "        t['type_index'] = pd.factorize(pd.concat([pd.Series(type_index),t['type']]))[0][len(type_index):]\n",
    "    else:\n",
    "        t['type_index'] = pd.factorize(t['type'])[0]\n",
    "    s = pd.concat([s,pd.get_dummies(s['atom'])], axis=1)\n",
    "\n",
    "    max_items = 785836 if has_y else 422550\n",
    "    max_atoms = int(s.atom_index.max() + 1)\n",
    "\n",
    "    if has_y:\n",
    "        contributions = ['fc','sd','pso','dso']\n",
    "        magnetic_tensors = ['XX','YX','ZX','XY','YY','ZY','XZ','YZ','ZZ']\n",
    "        XYZ = ['X','Y','Z']\n",
    "    xyz = ['x', 'y', 'z']\n",
    "    a_hot = ['C','F','H','N','O']\n",
    "    \n",
    "    x_xyz   = np.zeros((max_items,len(xyz),  max_atoms), dtype=np.float32)\n",
    "    x_a_hot = np.zeros((max_items,len(a_hot),max_atoms), dtype=np.float32)\n",
    "    x_type  = np.zeros((max_items,1,         max_atoms), dtype=np.float32)\n",
    "\n",
    "    if has_y:\n",
    "        y_scalar   = np.zeros((max_items,len(contributions)   ,max_atoms), dtype=np.float32)\n",
    "        y_magnetic = np.zeros((max_items,len(magnetic_tensors),max_atoms), dtype=np.float32)\n",
    "        y_mulliken = np.zeros((max_items,1                    ,max_atoms), dtype=np.float32)\n",
    "\n",
    "        y_dipole   = np.zeros((max_items,len(XYZ)), dtype=np.float32)\n",
    "        y_potential= np.zeros((max_items,1              ), dtype=np.float32)\n",
    "\n",
    "        y_magnetic[...] = np.nan\n",
    "        y_mulliken[...] = np.nan\n",
    "    else:\n",
    "        xt_ids = np.zeros((max_items, max_atoms), dtype=np.int32)\n",
    "\n",
    "\n",
    "    m = np.zeros((max_items,), dtype=np.int32)\n",
    "    i = j = 0\n",
    "    \n",
    "    for (m_name, m_index) ,m_group in tqdm(t.groupby(['molecule_name', 'molecule_index'])):\n",
    "        ss = s[s.molecule_name==m_name]\n",
    "        n_atoms = len(ss)\n",
    "        if has_y:\n",
    "            magnetic = magnetic_shielding[\n",
    "                    (magnetic_shielding['molecule_name']==m_name)][magnetic_tensors].values.T\n",
    "\n",
    "            mulliken = mulliken_charges[\n",
    "                    (mulliken_charges['molecule_name']==m_name)]['mulliken_charge'].values.T\n",
    "\n",
    "            scs = scalar_couplings[scalar_couplings['molecule_name']==m_name]\n",
    "            \n",
    "            y_dipole[j,:]= dipole_moments[dipole_moments['molecule_name']==m_name][XYZ].values\n",
    "            y_potential[j,:]=potential_energy[\n",
    "                potential_energy['molecule_name']==m_name]['potential_energy'].values\n",
    "        \n",
    "        for a_name,a_group in m_group.groupby('atom_index_0'):\n",
    "            \n",
    "            ref_a = ss[ss['atom_index']==a_name]\n",
    "            \n",
    "            x_xyz[i] = 0.\n",
    "            x_a_hot[i] = ref_a[a_hot].values.T\n",
    "            x_type[i] = -1\n",
    "\n",
    "            x_xyz[i,:,:n_atoms] = (ss[xyz].values-ref_a[xyz].values).T  # xyz \n",
    "            x_a_hot[i,:,:n_atoms] = ss[a_hot].T                  # a_hot\n",
    "            x_type[i,0,a_group['atom_index_1']] = a_group['type_index']  # type \n",
    "            \n",
    "            if has_y:\n",
    "                y_scalar[i,:,a_group['atom_index_1']] = scs[scs['atom_index_0']==a_name][contributions]\n",
    "                y_magnetic[i,:,:n_atoms] = magnetic\n",
    "                y_mulliken[i,:,:n_atoms] = mulliken\n",
    "            else:\n",
    "                xt_ids[i,a_group['atom_index_1']] = a_group['id']  \n",
    "\n",
    "            m[i] = m_index\n",
    "            i+=1\n",
    "        j += 1\n",
    "    assert i == max_items\n",
    "    print(i,max_items)\n",
    "    if has_y:\n",
    "        return x_xyz,x_a_hot,x_type, m , y_scalar, y_magnetic, y_mulliken, y_dipole, y_potential\n",
    "    else:\n",
    "        return x_xyz,x_a_hot,x_type, m, xt_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fname = Path('train.npz')\n",
    "try:\n",
    "    npzfile = np.load(train_fname)\n",
    "    x_xyz = npzfile['x_xyz']\n",
    "    x_a_hot = npzfile['x_a_hot']\n",
    "    x_type = npzfile['x_type']\n",
    "    y_scalar = npzfile['y_scalar']\n",
    "    y_magnetic = npzfile['y_magnetic']\n",
    "    y_mulliken = npzfile['y_mulliken']\n",
    "    y_dipole = npzfile['y_dipole']\n",
    "    y_potential = npzfile['y_potential']\n",
    "    m = npzfile['m']\n",
    "    max_items, max_atoms = x_xyz.shape[0], x_xyz.shape[-1]\n",
    "except:\n",
    "    x_xyz,x_a_hot,x_type, m , y_scalar, y_magnetic, y_mulliken, y_dipole, y_potential = \\\n",
    "        preprocess(train_fname.with_suffix('.csv'))\n",
    "    np.savez(train_fname, \n",
    "             x_xyz=x_xyz,\n",
    "             x_a_hot=x_a_hot,\n",
    "             x_type=x_type,\n",
    "             y_scalar=y_scalar,\n",
    "             y_magnetic=y_magnetic,\n",
    "             y_mulliken=y_mulliken,\n",
    "             y_dipole=y_dipole,\n",
    "             y_potential=y_potential,\n",
    "             m=m)\n",
    "n_types = int(x_type[~np.isnan(x_type)].max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fname = Path('test.npz')\n",
    "try:\n",
    "    npzfile = np.load(test_fname)\n",
    "    xt_xyz = npzfile['x_xyz']\n",
    "    xt_a_hot = npzfile['x_a_hot']\n",
    "    xt_type = npzfile['x_type']\n",
    "    mt = npzfile['m']\n",
    "    xt_ids = npzfile['x_ids']\n",
    "except:\n",
    "    train_csv = pd.read_csv(train_fname.with_suffix('.csv'))\n",
    "    xt_xyz,xt_a_hot,xt_type,mt,xt_ids = \\\n",
    "        preprocess(test_fname.with_suffix('.csv'), type_index = pd.factorize(train_csv['type'])[1])\n",
    "    np.savez(test_fname, \n",
    "             x_xyz=xt_xyz,\n",
    "             x_a_hot=xt_a_hot,\n",
    "             x_type=xt_type,\n",
    "             m=mt,\n",
    "             x_ids=xt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(785836, 3, 29),\n",
       " (785836, 5, 29),\n",
       " (785836, 1, 29),\n",
       " (785836, 4, 29),\n",
       " (785836, 9, 29),\n",
       " (785836, 1, 29),\n",
       " (785836, 3),\n",
       " (785836, 1),\n",
       " (785836,)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.shape for v in [x_xyz,x_a_hot,x_type, y_scalar, y_magnetic, y_mulliken, y_dipole, y_potential, m]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Do norm in FASTAI instead of here\n",
    "# TOCHECK: Filter only valid atoms (otherwise repeated atoms may skew stats)\n",
    "#xyz_mean, xyz_std = x_xyz.mean(axis=(0,2), keepdims=True),  x_xyz.std(axis=(0,2), keepdims=True)\n",
    "#x_xyz  = (x_xyz  - xyz_mean) / xyz_std\n",
    "#xt_xyz = (xt_xyz - xyz_mean) / xyz_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(422550, 3, 29), (422550, 5, 29), (422550, 1, 29), (422550,)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.shape for v in [xt_xyz,xt_a_hot,xt_type, mt]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = 0.1\n",
    "# from https://github.com/fxia22/pointnet.pytorch/blob/master/pointnet/model.py\n",
    "\n",
    "class STNkd(nn.Module):\n",
    "    def __init__(self, k=64):\n",
    "        super(STNkd, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k*k)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        #iden = torch.eye(self.k, dtype=x.dtype, device=x.device).view(1,self.k*self.k).expand((batchsize,-1))\n",
    "        #x = x + iden\n",
    "        x = x.view(-1, self.k, self.k)\n",
    "        return x\n",
    "\n",
    "class PointNetfeat(nn.Module):\n",
    "    def __init__(self, global_feat = True, input_transform = True, feature_transform = False):\n",
    "        super(PointNetfeat, self).__init__()\n",
    "        self.stn = STNkd(k=3) if input_transform else None\n",
    "        self.conv1 = torch.nn.Conv1d(9, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.global_feat = global_feat\n",
    "        self.feature_transform = feature_transform\n",
    "        if self.feature_transform:\n",
    "            self.fstn = STNkd(k=64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n_pts = x.size()[2]\n",
    "        if self.stn is not None:\n",
    "            x_xyz = x[:,:3,...].clone()\n",
    "            trans = self.stn(x_xyz)\n",
    "            x[:,:3,:] = torch.bmm(trans, x_xyz)\n",
    "        else:\n",
    "            trans = torch.eye(\n",
    "                self.k, dtype=x.dtype, device=x.device).view(1,self.k*self.k).expand((batchsize,-1))\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        if self.feature_transform:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = x.transpose(2,1)\n",
    "            x = torch.bmm(x, trans_feat)\n",
    "            x = x.transpose(2,1)\n",
    "        else:\n",
    "            trans_feat = None\n",
    "\n",
    "        pointfeat = x\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "        if self.global_feat:\n",
    "            return x, trans, trans_feat\n",
    "        else:\n",
    "            x = x.view(-1, 1024, 1).expand(-1, -1, n_pts)\n",
    "            return torch.cat([x, pointfeat], 1), trans, trans_feat\n",
    "    \n",
    "class PointNetDenseReg(nn.Module):\n",
    "    def __init__(self, k = 2, feature_transform=False):\n",
    "        super(PointNetDenseReg, self).__init__()\n",
    "        self.k = k\n",
    "        self.feature_transform=feature_transform\n",
    "        self.feat = PointNetfeat(global_feat=False, feature_transform=feature_transform)\n",
    "        self.conv1 = torch.nn.Conv1d(1088, 512, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(512, 256, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(256, 128, 1)\n",
    "        self.conv4 = torch.nn.Conv1d(128, self.k, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        n_pts = x.size()[2]\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.dropout(x,p=dropout_rate)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.conv4(x)\n",
    "        #x = x.transpose(2,1).contiguous()\n",
    "        #x = x.view(batchsize, n_pts, self.k)\n",
    "        return x, trans, trans_feat if self.feature_transform else trans\n",
    "\n",
    "def feature_transform_regularizer(trans):\n",
    "    d = trans.size()[1]\n",
    "    batchsize = trans.size()[0]\n",
    "    I = torch.eye(d, dtype=trans.dtype, device=trans.device).unsqueeze(0)\n",
    "    loss = torch.mean(torch.norm(torch.bmm(trans, trans.transpose(2,1)) - I, dim=(1,2)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeItem(ItemBase):\n",
    "    def __init__(self,i,xyz,a_hot,type): \n",
    "        self.i, self.xyz,self.a_ahot,self.type = i,xyz,a_hot,type\n",
    "        self.data = torch.cat([Tensor(xyz), Tensor(self.a_ahot),Tensor(self.type)], dim=0)\n",
    "    def __str__(self):\n",
    "        # TODO: count n_atoms correctly. \n",
    "        n_atoms = np.count_nonzero(np.sum(np.absolute(self.xyz), axis=0))+1\n",
    "        n_couplings = np.sum((self.type!=-1))\n",
    "        return f'{self.i} {n_atoms} atoms {n_couplings} couplings'\n",
    "    \n",
    "class ScalarCouplingItem(ItemBase):\n",
    "    def __init__(self,scalar,magnetic,mulliken,dipole,potential,**kwargs): \n",
    "        self.scalar,self.magnetic,self.mulliken,self.dipole,self.potential = \\\n",
    "            scalar,magnetic,mulliken,dipole,potential\n",
    "        self.data = Tensor(np.sum(scalar, axis=0))\n",
    "    def __str__(self):\n",
    "        res, spacer, n_couplings = '', '', 0\n",
    "        for s in self.data:\n",
    "            if s==0.: spacer = ' * '\n",
    "            else: \n",
    "                res += f'{spacer}{s:.4f}'\n",
    "                spacer = ' '\n",
    "                n_couplings +=1\n",
    "        return f'{n_couplings}: {res}'\n",
    "    def __hash__(self): return hash(str(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMAEMaskedLoss(input_outputs,target,feature_transform_regularizer_weight=0.1):\n",
    "    input, output, trans, trans_feat = input_outputs\n",
    "    loss = 0.\n",
    "    n = 0\n",
    "    for type in range(n_types):\n",
    "        mask = (input[:,8,:] == type)\n",
    "        if mask.sum() > 0:\n",
    "            _output,_target = output[:,0,:], target\n",
    "            loss += torch.log((_output[mask] - _target[mask]).abs().mean()+1e-9)\n",
    "            n+=1\n",
    "    return loss/n + feature_transform_regularizer(trans)*feature_transform_regularizer_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScalarCouplingList(ItemList):\n",
    "    def __init__(self, items:Iterator, **kwargs):\n",
    "        super().__init__(items, **kwargs)\n",
    "        self.c = 1\n",
    "        self.loss_func = LMAEMaskedLoss\n",
    "\n",
    "    def get(self, i):\n",
    "        o = super().get(i)\n",
    "        return ScalarCouplingItem(*o)\n",
    "\n",
    "    def reconstruct(self,t): return 0; # TODO for viz !!!! ScalarCouplingItem(t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ItemList(items=(MoleculeItem(i,*v) for i,v in enumerate(zip(x_xyz,x_a_hot,x_type))),\n",
    "                label_cls=ScalarCouplingItem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "_, idx_valid_split = train_test_split(range(m.max()+1), test_size=0.1, random_state=13)\n",
    "idx_valid_split = np.argwhere(np.isin(m, idx_valid_split)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ItemLists;\n",
       "\n",
       "Train: ItemList (707619 items)\n",
       "0 5 atoms 4 couplings,1 5 atoms 3 couplings,2 5 atoms 2 couplings,3 5 atoms 1 couplings,4 4 atoms 3 couplings\n",
       "Path: .;\n",
       "\n",
       "Valid: ItemList (78217 items)\n",
       "9 8 atoms 7 couplings,10 8 atoms 6 couplings,11 8 atoms 5 couplings,12 8 atoms 4 couplings,13 8 atoms 3 couplings\n",
       "Path: .;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.split_by_idx(idx_valid_split)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.label_from_func(\n",
    "    func=lambda o: (y_scalar[o.i], y_magnetic[o.i], y_mulliken[o.i], y_dipole[o.i], y_potential[o.i]),\n",
    "    label_cls=ScalarCouplingList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.databunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChemCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def on_epoch_begin(self,**kwargs):\n",
    "        pass # PAVEL -> at some point do learner.opt.clear() or equivalent reset opt internals \n",
    "    def on_batch_begin(self,**kwargs):\n",
    "        \"Save the last_input (i.e. current input) for on_loss_begin_callback\"\n",
    "        self.last_input = kwargs['last_input']\n",
    "    def on_loss_begin(self, last_output:Tuple[Tensor,Tensor,Tensor], **kwargs):\n",
    "        \"Add last_input to last_output, i.e. input to loss function b/c we need it\"\n",
    "        return {'last_output': (self.last_input, *last_output)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net, learner = None,None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "net = PointNetDenseReg(k = 1)\n",
    "learner = Learner(data,net, callbacks=[ChemCallback()], \n",
    "                  loss_func=partial(LMAEMaskedLoss,feature_transform_regularizer_weight=0.),\n",
    "                  metrics=[partial(LMAEMaskedLoss,feature_transform_regularizer_weight=0.)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = learner.to_parallel()#.to_fp16() # to_parallel/fp_16 does not converge as well. why?\n",
    "data.batch_size = 4096*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 4.79E-02\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VNXdx/HPb7KHbEACYQthR0BkCQgqCnXDasWtVSvgglqsdbe21af1eeyibbVWa12oICqWVlHbat2tiiiy74uC7IuQAIEsZD/PHzNgpEkYIDN3Jvm+X695OXPvnblf4oQf95x7zjHnHCIiIofj8zqAiIhEBxUMEREJigqGiIgERQVDRESCooIhIiJBUcEQEZGgqGCIiEhQVDBERCQoKhgiIhKUWK8DNKbMzEyXm5vrdQwRkaixYMGCAudcVjDHNqmCkZuby/z5872OISISNcxsY7DHqklKRESCooIhIiJBUcEQEZGgqGCIiEhQVDBERCQoKhgiIhIUFQwREQlKyAqGmXUysw/MbJWZrTCzW+o4xszsUTNba2ZLzWxQrX1XmtmawOPKUOUUEYlm767cwZMffRmWc4XyCqMKuMM5dxwwDLjRzPoccsw5QI/A43rgCQAzawXcC5wIDAXuNbOWIcwqIhKV3lu5g6mfbAjLuUJWMJxz251zCwPPi4BVQIdDDhsDPOf8PgMyzKwdcDbwrnNut3NuD/AuMDpUWUVEolVxeRUpieGZtCMsfRhmlgsMBOYcsqsDsLnW6y2BbfVtFxGRWorKq0hJaCIFw8xSgJeBW51z+w7dXcdbXAPb6/r8681svpnNz8/PP7awIiJRprisktSmcIVhZnH4i8ULzrlX6jhkC9Cp1uuOwLYGtv8X59wk51yecy4vKyuoCRdFRJqM4qZwhWFmBkwGVjnn/lDPYf8CxgfulhoG7HXObQfeBs4ys5aBzu6zAttERKSW4rLwFYxQnuVkYBywzMwWB7bdDeQAOOeeBN4Avg2sBUqBqwP7dpvZL4F5gffd55zbHcKsIiJRqSiMnd4hO4tzbhZ190XUPsYBN9azbwowJQTRRESaBOccxeVVpEZ7k5SIiIRWaUU1ztG0bqsVEZHGV1xeBUBKQlxYzqeCISISpYrKAgVDVxgiItKQA1cY6sMQEZEGFYf5CiM8Z4lCG3eV8OHn+Xz0RT6V1TUMzW3FiV1bc0KndBJiY7yOJyJCcXklQJMYhxE1Tn/oQyqrHXExRlyMj5KKKjbv3g9A59bJJMXF8If3vsA5SIj1ccZxbblkcEdG9MgkNkYXaSLijYN9GCoY4TO0Syv2V1RTWeOorKohNsaYcHIXRvZqQ25mCwAKSyuYu343s9YW8NqSbfx72XbapCZwXv/2DO7ckv4d0+nYMgn/AHcRkdA72IehJqnwuf+i/oc9JiM5nrP6ZnNW32z+59w+/Gf1TmYs2MK0zzYy5ZP1ALRqEc+IHplcMrgjJ3XLJMb338WjqrqGWWsLeGPZdnxm5LROpnOrFnRvk0LPtikqOCIStAN9GC10hRG54mN9jO6Xzeh+2ZRXVfP5V0Us2bKXxZsKeXflV/xz8TbapSdy/gntaZOWSFyMEevzsXZnMf9aso2C4nJSE2NJiPVRUFxx8HOP75DOVSflct4J7dRPIiKHVVxeRWKcj7gwNY2rYByjhNgY+nfMoH/HDMYN60xZZT/eX7WTlxZs5i8fr6Om1qTscTHGt3q34cKBHRnVO4uE2BiKy6vYtKuUBRt38+zsjdzx0hLuf3MVZxzXluz0RNqkJtI2LYGcVsnktE5usJDsKalgzc5ierVNJT05PAN5RMQ7/rUwwve7roLRyBLjYji3fzvO7d+Osspqyiqrqax2VNXUkJIQS2riN//npiTE0qd9Gn3apzF2WGc+WbuLqZ9u4L1VO75x9QFgBu3Tk8hplUzrlHgyUxJomRzP1sJSFmzcw5f5JQeP69c+nZO6teaEThm0bhFP65R4WrdIICM5Ts1eIk1EcVlV2PovQAUjpBLjYkiMC75pycw4pUcmp/TIBKCyuoaC4nK27y1j065S1heUsGFXCZt3l7J86152lVRQVFZFRnIcg3NactGgjvRsm8qKbXv59MtdTPlkPZXV31x3KiM5jj7t0jiuXRq9s1Pp1CqZDhlJtEtP1B1fIlEmnGthgApGRIuL8dEuPYl26UkMymlZ5zEVVTXE+gxfrQ72M/u05dYzYH9FNesLSthdUsGuknIKiitYu7OYldv3Me2zjZRX1Rx8j8/ghE4ZXD+iK2f1za6zw15EIks418IAFYyoFx9b/1VBUnwMfdqn1bmvqrqGTbtL2Vq4n6179rN5TymvLdnODS8spGtmC647tSsXDuxwRFdIIhJeReVVdGyZFLbzqWA0U7ExPrpmpdA1K+XgttvP7MWby7fz1Efr+Nkry3jonc8ZNyyXscNyaJ2S4GFaEalLcXklqQmpYTufCoYcFOMzzuvfnnOPb8fsL3fxl4/X8fB7X/D4h2sZM6A95/Rrx/BurXXVIRIhisvCt9oeqGBIHcyMk7pnclL3TNbsKGLyrPX8a8k2Xpy/haS4GE7pkcnpvdswqncb2qYleh1XpFk6sNqe+jAkYvRom8oDF/fn/8b05bN1u3lv5Q7eX7WDd1fuAKBfhzS+1bstV5yYo+IhEkblVTVUVjtdYUjkSYiN4bSeWZzWM4v7xvTl8x1FvL9qJx+s3slj/1nDkx99yWVDOjHxtG60zwhfJ5xIc/X1ansqGBLBzIze2Wn0zk7jxlHd2bSrlCc+Wstf52xi+txNXDK4Ez8c2Y1OrZK9jirSZBWHeaZa0AJK0ghyWidz/0X9+fDHI/leXideXrCFUQ9+yE9fXsqmXaVexxNpkry4wlDBkEbTsWUyv77weD66ayRXnJjDK4u2MuqhD/n5P5azp6Ti8B8gIkEL93reoIIhIdAuPYn/G9OPmT8exfeH5vDXuZsY+eCHTP1kPZXVNYf/ABE5rK/X8w7f5IMqGBIy2emJ/PKCfrxx8wj6dUjjf19byeg/zuS52RvYW1rpdTyRqHZweVZdYUhT0is7lWkTTuSpcYNJiI3hF/9cwdDfvMetf1vE8q17vY4nEpW86PTWXVISFmbG2X2zObtvNsu37uXv8zbzj8VbeX3pdu459ziuOilX066LHIGiMC/PCrrCEA/065DOLy/ox6yffIuRvdrwf6+t5KbpiygJ/AKIyOEVl1UR6zMSGpiAtLGpYIhn0pPimDRuMD8Z3Zs3lm3n/MdmsWKbmqhEglFc7p9HKpxX5iErGGY2xcx2mtnyeva3NLNXzWypmc01s3619t1mZivMbLmZTTczzTnRRPl8xg0juzHt2hPZV1bFmMc+4cG3P6e8qtrraCIRLdxrYUBorzCmAqMb2H83sNg51x8YDzwCYGYdgJuBPOdcPyAGuCyEOSUCnNQtk3dvO5ULBnbgsQ/Wcu6js/hs3S6cc4d/s0gzVBTmiQchhJ3ezrmZZpbbwCF9gPsDx642s1wza1srV5KZVQLJwLZQ5ZTIkZEcz4PfPYHvnNCeu19ZxmWTPqNNagIje2UxqlcbRvZqQ1K8plYXgfCv5w3e9mEsAS4CMLOhQGego3NuK/AgsAnYDux1zr3jWUoJu9N6ZvHObafy+0v6M6RLK95c/hU3vLCQM/7wETO/yPc6nkhECPfU5uBtwXgAaGlmi4GbgEVAlZm1BMYAXYD2QAszG1vfh5jZ9WY238zm5+frL5OmokVCLN/N68Sfvz+IRT8/k2evGUpCnI/xU+Zy50tLNPBPmj1/p3f4RnmDhwXDObfPOXe1c24A/j6MLGA9cAaw3jmX75yrBF4BTmrgcyY55/Kcc3lZWVlhyS7hFRvj47SeWbxx8whuHNWNVxdt5YyHP+KD1Tu9jibimaIm1undIDPLMLP4wMtrgZnOuX34m6KGmVmy+e8XOx1Y5VVOiRyJcTH8+Oze/PPGk2ndIp6rp87jf/6xjP0VuqNKmp/i8sqm04dhZtOB2UAvM9tiZhPMbKKZTQwcchywwsxWA+cAtwA45+YAM4CFwLJAxkmhyinRp1+HdP5x48lcN6ILL8zZxLmPfszSLYVexxIJm8rqGsoqa5rUXVKXH2b/bKBHPfvuBe4NRS5pGhLjYrjn3D6M6t2GO15cwsVPfMovvtOXsSfmaIoRafJKPFgLAzTSW6LcSd0yefOWEZzSPZOf/2M5d7y0RE1U0uR5sRYGqGBIE5CRHM/kK4dw2xk9eXXRVi58/BM2FJR4HUskZL5eC0MFQ+SI+XzGLWf04JmrhrB9bxnn/WkW/1663etYIiFxcHlWXWGIHL2Rvdrw75tPoXubFG7860J+8c/llFWqiUqaFi/WwgAVDGmCOrZM5sUfDOe6EV14bvZGLn7iUy3UJE2KF2thgAqGNFHxsT7uObcPfxmfx459ZXznsVn8/B/LNUJcmoSvrzCayUhvkXA4s09b3r9jJFcOz+WFORsZ9dCHzFiwRbPgSlTzYj1vUMGQZiA9KY7/Pb8vr910Crmtk7nzpSWMnzKXzbtLvY4mclSKy6owg+S48M7erIIhzUbf9unMmHgSvxzTl4Ub93D2H2cyZdZ6amp0tSHRpai8ipT4WHy+8A5SVcGQZsXnM8YNz+Wd209jaJdW3Pf6Sq55dh6FpRVeRxMJWnFZVdibo0AFQ5qpDhlJPHPVEH51QT8+WVvAd7SeuEQRL9bCABUMacbMjLHDOvP3Hwynsspx0eOfqkNcooJ/LQwVDJGwG5TTktduOoWBORnc+dISbpi2kPyicq9jidTLi7UwQAVDBICs1ASmTTiRn4zuzX9W7+Sshz/itSXbdLUhEam4PPzreYMKhshBsTE+bhjZjX/ffAo5rVtw0/RF3P3qMt1FJRGnWFcYIpGhR9tUXp44nImndWP63M389JWlKhoSUfyd3uEd5Q0hXEBJJJrFxvj4yehexMf6ePT9NQA8cFH/sN/3LnKomhpHSYU3nd4qGCL1MDNuP7MnBjwSKBr3X9SfGBUN8VBpZTXOhX8tDFDBEDms287sCfiLRn5ROY9cPpC0xPA3B4hArYkH1ektEpluO7Mnv7qgHx+vKeDCP3/Ceq3oJx45OPGgOr1FItfYYZ2Zdu2J7C6pYMxjs5j5Rb7XkaQZ2rvfm5lqQQVD5IgM69qaf/3oFNpnJHHVM3N5+uN1GqshYbVxl3+W5U4tk8J+bhUMkSPUqVUyL99wEmf1yeZX/17FHS8t0TKwEjYbCkrwmf97GG4qGCJHoUVCLI9fMYjbz+zJKwu3cumkz9ixr8zrWNIMrCsooUPLJBJiw7sWBqhgiBw1n8+4+fQePDVuMGt2FHHxE5+yQZ3hEmIbdpWQ27qFJ+dWwRA5Rmf3zWb6dcMoKa/ikidns3LbPq8jSRPlnGNDQSldM1UwRKLWCZ0yeGnicOJijEsnzWb+ht1eR5ImqKC4guLyKnJVMESiW/c2qcy44SSyUhIYO3kOc9bt8jqSNDEHxv+oYIg0AR0yknhx4nA6ZCQx4dn5LNlc6HUkaUIO9JE1uSYpM5tiZjvNbHk9+1ua2atmttTM5ppZv1r7MsxshpmtNrNVZjY8VDlFGltmSgIvXDuMli3iGD9lLqu2q09DGsf6XSXE+owOGeEfgwGhvcKYCoxuYP/dwGLnXH9gPPBIrX2PAG8553oDJwCrQhVSJBSy0xP567XDSIqLYdzkOazLL/Y6kjQB6/NLyGmVTGyMN41DITurc24m0FDPXx/g/cCxq4FcM2trZmnAqcDkwL4K55yu6yXqdGqVzLRrT8Q5uOLpOWzeXep1JIlyG3aV0MWj5ijwtg9jCXARgJkNBToDHYGuQD7wjJktMrOnzcy7n5DIMejeJoXnJ5xISXkVYyfPYacG98lRqqlx/jEYzbRgPAC0NLPFwE3AIqAK/5Trg4AnnHMDgRLgp/V9iJldb2bzzWx+fr4mg5PI06d9GlOvGUpBUTlXPD2H3SUVXkeSKLSjqIyyyprmWTCcc/ucc1c75wbg78PIAtYDW4Atzrk5gUNn4C8g9X3OJOdcnnMuLysrK+S5RY7GoJyWPH3lEDbtLmX8lDnsK6v0OpJEmfX53t4hBR4WjMCdUPGBl9cCMwNF5Ctgs5n1Cuw7HVjpSUiRRjS8W2ueHDeY1duLuGHaAiqqaryOJFFk/S5vx2BAaG+rnQ7MBnqZ2RYzm2BmE81sYuCQ44AVZrYaOAe4pdbbbwJeMLOlwADgN6HKKRJOo3q14YGL+/PJ2l3c8+oyTY0uQdtQUEJCrI92aYmeZQjZChzOucsPs3820KOefYuBvFDkEvHaJYM7sml3KY++v4bOrZP50bfq/DUQ+Yb1Bf5JB30erimvNb1FPHDbGT3YsruUB9/5go4tk7lgYAevI0mEW19QQvc2KZ5m0NQgIh4wM+6/+HhO7NKKu2YsZcFGTVYo9auucWzaXepp/wWoYIh4JiE2hqfGDaZdRiI/eH4BWwv3ex1JItTWPfuprHae3iEFKhginspIjmfylXmUV9Zw7bPzKSmv8jqSRKCDd0h5tHDSASoYIh7r3iaVP31/IJ9/tY/bX1xMTY3unJJvOjBLrZfTgoAKhkhEGNmrDfec24e3V+zg4fe+8DqORJj1BSW0iI8hKzXB0xxBFQwz62ZmCYHnI83sZjPLCG00keblmpNzuTSvE3/6z1reWLbd6zgSQdYX+OeQMvPulloI/grjZaDazLrjn0W2C/DXkKUSaYbMjPsu6MugnAzueHGJ1tGQgzbvKaVz62SvYwRdMGqcc1XAhcAfnXO3Ae1CF0ukeUqIjeHJsYNJS4rluufma6JCAaCwtJJWLeIPf2CIBVswKs3scuBK4PXAtrjQRBJp3tqkJfLUuDx2FpVz4wsLqazWnFPNmXOOvfsrSU/y/q/cYAvG1cBw4NfOufVm1gWYFrpYIs3bgE4Z3H/h8cxet4tf/1sLTjZnxeVVVNc4MpK8v8IIamoQ59xK4Gbwr8UNpDrnHghlMJHm7uLBHVm5fR+TZ62nT/s0vpfXyetI4oHCUv9U+OnJUXKFYWYfmlmambXCv1LeM2b2h9BGE5GfndObU7pn8j+vLmfhpj1exxEP7N3vLxgZUdQkle6c24d/SdVnnHODgTNCF0tEAGJjfDz2/YFkpycy8fkF7NASr83OgYIRTX0YsWbWDvgeX3d6i0gYZCTH85fxeRSXV3Hdc5o+pLk50CSVkex9H0awBeM+4G3gS+fcPDPrCqwJXSwRqa1XdiqPXjaQ5Vv3csMLC7VaXzNSuN9/a3VGtPRhOOdecs71d87dEHi9zjl3cWijiUhtZ/Rpy/0XHc/ML/K5a8YSzTnVTERdk5SZdTSzV81sp5ntMLOXzaxjqMOJyDddOiSHH5/di38s3sav31ilJV6bgb2llSTE+kiMi/E6StBNUs8A/wLaAx2A1wLbRCTMfjiyG1edlMvkWet58qN1XseRECssrYyI5igIfonWLOdc7QIx1cxuDUUgEWmYmfGL8/qwu6SC3761mpbJcVw2NMfrWBIihfsrImLQHgR/hVFgZmPNLCbwGAvsCmUwEamfz2c8+N0TOK1nFne/uoy3lmt226YqUqYFgeALxjX4b6n9CtgOXIJ/uhAR8Uh8rI8nxg5iQKcMbp6+mE/XFngdSUKgsLQyIkZ5Q/B3SW1yzp3vnMtyzrVxzl2AfxCfiHgoOT6WKVcNoUtmC657bj4LNu72OpI0sr37KyNilDcc24p7tzdaChE5ahnJ8Tw/YSht0hK5cso8TSHSxERjk1RdvF36SUQOapOWyPTrhpGZEs+Vk+eyeHOh15GkEZRXVVNaUR0xd0kdS8HQDeAiESQ7PZHp1w+jVUo84ybPYYmKRtQ7OGgvAqYFgcMUDDMrMrN9dTyK8I/JEJEI0i49ienXDSMjOY5rps5j8+5SryPJMdhbGjkz1cJhCoZzLtU5l1bHI9U5F+wYDhEJo/YZSUy9eiiV1TVc99x8ijVZYdSKpGlB4NiapEQkQnXLSuHPVwxizc5ibv3bIqo171RU+nqm2iZeMMxsSmDuqeX17G8ZmJ9qqZnNNbN+h+yPMbNFZqbp1EWOwogeWfzivD68t2onv3t7tddx5CgUHlw8KQr6MI7RVGB0A/vvBhY75/oD44FHDtl/C6DFjEWOwfjhnRk7LIenPlrHnz9Yq8kKo0yzaZJyzs0EGhpF1Ad4P3DsaiDXzNqCf3Zc4Fzg6VDlE2kOzIx7v9OX809oz+/f/py7X11GZbXW0ogWe0srMIPUxMjoMvayD2MJgdHiZjYU6AwcmDL9j8BdgL7ZIscoLsbHHy8dwI9GdWf63M1MeHY+RWWVXseSIBQGBu35fJEx7M3LgvEA0NLMFgM3AYuAKjM7D9jpnFsQzIeY2fVmNt/M5ufn54cwrkj08vmMO8/uxW8vPp5P1hZw0eOfsmCjRoRHusLSyJkWBDwsGM65fc65q51zA/D3YWQB64GTgfPNbAPwN+BbZjatgc+Z5JzLc87lZWVlhSO6SNS6dEgOz10zlOLyKi5+4lN+9spSCksrvI4l9YikaUHAw4JhZhlmdqDr/1pgZqCI/Mw519E5lwtcBvzHOTfWq5wiTc3J3TN57/bTuG5EF16cv4VvPfQRH36+0+tYUofC/ZURM8obQntb7XRgNtDLzLaY2QQzm2hmEwOHHAesMLPVwDn474oSkTBokRDLPef24fWbTqFNagI3vrCQL3YUeR1LDrG3tCKimqRC1vXunLv8MPtnAz0Oc8yHwIeNl0pEajuuXRpTrx7Kdx6bxXXPzedfN54SMWsvSGBq8wj6/6GR3iLNXHZ6Ik+OHcS2wv38aPpCjQqPEDU1Tn0YIhJ5BnduxX1j+vHxmgKNCo8QReVV1LjIGbQHIWySEpHocvnQHJZv3ctTH62jT7s0xgzo4HWkZu3gTLXNodNbRKLPvd/py9DcVtw1YynLtuz1Ok6zFmnTgoAKhojUEh/r4/Gxg2jdIp7rn59PflG515GarcL9/vEx6vQWkYiVmZLApPF57C6p4IcvLKCiSjP0eKEwwhZPAhUMEalDvw7p/O6S/szbsIf7Xl/hdZxm6evlWVUwRCTCjRnQgR+c2pVpn23itSXbvI7T7KgPQ0Siyp1n92JQTgY/e2UZG3eVeB2nWSksrSApLoaE2BivoxykgiEi9YqL8fHo5QPxGdw0fZH6M8KosDSyRnmDCoaIHEbHlsn87pL+LN2yl9++pUF94RJpo7xBBUNEgjC6XzvGD+/M5FnreWv5dq/jNAuFKhgiEq3u/vZxDOiUwc1/W8xn63Z5HafJ26smKRGJVolxMTxz1RByWiVz3bPzWb5VI8FDae/+SjKSImdaEFDBEJEj0LJFPM9dM5TUxFiuemYuGwp051SoFO6viKgxGKCCISJHqH1GEs9NOJHqGse4KXPYua/M60hNTlllNWWVNerDEJHo171NCs9cPZRdxRWMmzz34Myq0jgODNpTH4aINAkDOmUwaVwe6wqKuXrqXEorqryO1GRE4ihvUMEQkWNwSo9MHrlsIIs3F3LDtIUa2NdIvp54UJ3eItKEfPv4dvz6wuP56It8fvrKUpzTEq/HqrA08qY2B624JyKN4PKhOXy1t4xH3l/DwE4ZjBue63WkqKYmKRFp0m45vQejemVx3+srWbhpj9dxolpBsf8KQ7fVikiT5PMZD186gLZpidz4wkJ2FWu1vqM184t8uma1IDUhshqBVDBEpNFkJMfz5NjB7Cqp4Oa/LaK6Rv0ZR6qguJw563dx7vHtMDOv43yDCoaINKp+HdL51Zh+fLJ2F5NmrvM6TtR5e8VX1Dj/zQSRRgVDRBrd94Z0YnTfbB5+7wvW5Rd7HSeqvLFsO10zW9A7O9XrKP9FBUNEQuK+MX1JjPXxk5eXUqOmqaDsKi5n9pe7+HYENkeBCoaIhEibtER+fl4f5m3YwwtzNnodJyq8s3IHNQ7OOT7b6yh1UsEQkZC5ZHBHRvTI5IE3V7O1cL/XcSLeG8u2k9s6mT7t0ryOUqeQFQwzm2JmO81seT37W5rZq2a21Mzmmlm/wPZOZvaBma0ysxVmdkuoMopIaJkZv7nweBxwz6vLNAq8AbtLKvg0gpujILRXGFOB0Q3svxtY7JzrD4wHHglsrwLucM4dBwwDbjSzPiHMKSIh1KlVMnee1YsPP8/nnZU7vI4Tsd5Z8RXVNS4i7446IGQFwzk3E9jdwCF9gPcDx64Gcs2srXNuu3NuYWB7EbAK6BCqnCISeuOHd6ZX21QmP/seVRNvgLQ08Pn8//3hD+HLL72O6Lk3ln9FTqtk+raPzOYo8LYPYwlwEYCZDQU6Ax1rH2BmucBAYE6Ys4lII4qN8fFw+jamPnwt9vTTUFQEzvn/+/TT0L8/vPmm1zE988HqnXy6tiCim6PA24LxANDSzBYDNwGL8DdHAWBmKcDLwK3OuX31fYiZXW9m881sfn5+fqgzi8jR+PJL+tw0geSqcmKqD1k3o7ISSkvhkkua3ZWGc46/zFzHNc/Oo1d2KteO6OJ1pAZ5VjCcc/ucc1c75wbg78PIAtYDmFkc/mLxgnPulcN8ziTnXJ5zLi8rKyvkuUXkKDz0kL8wNKSyEh5+ODx5IkB5VTV3zVjKr99YxTn9snlp4nAyUxK8jtUgzwqGmWWY2YHVQa4FZjrn9pn/emwysMo59wev8olII5o2LbiC8fzz4ckTAe795wpeWrCFm0/vwWOXDyI5PrImGqxLyBKa2XRgJJBpZluAe4E4AOfck8BxwHNmVg2sBCYE3noyMA5YFmiuArjbOfdGqLKKSIgVBzk9SLDHRTnnHO+t2sH5J7Tn9jN7eh0naCErGM65yw+zfzbQo47ts4DI7fURkSOXkuLv4A7muGZg465SCoorGNqllddRjohGeotI6I0dC3GHWQwoLg7GjQtPHo/N3+hfYCovt6XHSY6MCoaIhN4ddwRXMG67LTx5PLZg425SE2Pp2SbyZqRtiAqGiIRet24wYwYkJ/9X4aiOjfVvnzHDf1wzMH/DHgbltMTni67WdxUMEQmPc86BpUvh+usPjvQuSWzBa0PPpWbxEv/+ZqCwtII1O4vXiWTYAAAPcklEQVQZEmXNUaCCISLh1K0bPPYY7N0L1dW88+lqbh1xHZ+Q7nWysFm4yd9/MbhzdHV4gwqGiHjo28e3o3WLeJ79tPmslzF/wx5ifcaAThleRzliKhgi4pmE2BguH5rD+6t3sGzLXq/jhMX8jXvo2z6NpPgYr6McMRUMEfHU1Sfn0j49iQnPzmNbE19kqaKqhiWbC6OyOQpUMETEY61TEphy1RD2V1RzzdR5FJUdZgqRKLZi217Kq2qibvzFASoYIuK5Xtmp/PmKQazZWcyP/rqIquoaryOFxIIDA/Y6q2CIiBy1U3tm8asL+vHRF/lc9cw8nvlkPQs37aGsstrraI1m/oY9dGqVRJu0RK+jHJXInx5RRJqNy4fmsHd/Jc98sp5ZawsAiIsxbhzVnVtO7xHRiwsdjnOO+Rv3MKJHptdRjpoKhohElImndWPiad34am8ZizcX8trSbfzxvTWs3VnMg989gcS46Lu7CA5MOFjO4ChtjgIVDBGJUNnpiYxOz+bsvm05vkM6v31rNZt3l/LUuDzKKqtZ/dU+Vn9VxJY9+ykoLqeguJyKqhr+59w+nNoz8hZTm7thNxB9Ew7WpoIhIhHNzJh4Wje6Zrbg1r8vZtj97x/c5zNom5ZIZkoCWSkJbNhVyvXPz2fahBPJy42sW1c/XlNAZkoCvdpG14SDtalgiEhUOKtvNi/fcBKvLdlG59bJ9M5Oo2fb1G8MgCsoLud7T87m6mfmMf36YfTrEBlTjtTUOGatyWdUrzZR3Q+ju6REJGoc1y6Nu0b35tIhOZzQKeO/RktnpiQw7doTSUuKY/yUuazdGRkr+K3Yto89pZWM6Bm9Hd6ggiEiTUz7jCSenzAUn8EVT3/Gl/neF42Za/IBOKV75PWtHAkVDBFpcrpmpTDt2hOprnFc+tRsVn+1z9M8H6/Jp0+7NLJSEzzNcaxUMESkSeqdncbffzCcWJ+PyyZ9xtIthZ7kKCmvYsHGPVHfHAUqGCLShHXLSuHFHwwnJSGWK/4yh8Wbw180Plu3i8pqx6k9ors5ClQwRKSJy2mdzIs/GE5aUhx3zVgS9nmqPl5TQGKcL6oH7B2ggiEiTV77jCR+ft5xfLGjmL/P3xzWc89ck8+wrq2jdoR6bSoYItIsnN03m6FdWvGHd75gX5imUN+yp5R1+SWMaALNUaCCISLNhJnx83P7sKukgsc/+DIs55y1xj+B4qlRPOFgbSoYItJsHN8xnYsGdWDKrPVs3l0a8vN9vKaA7LREurdJCfm5wkEFQ0SalbvO7o3PB799a3VIz1NZXcOstQWM6JEZ1dOB1KaCISLNSnZ6Ij84tRuvL93Oywu2hOw8c9btZu/+Ss7o0zZk5wg3TT4oIs3ODSO7sWDjHn48YwlxsT7OP6F9o5/jrRXbSYqL4bQInGr9aIXsCsPMppjZTjNbXs/+lmb2qpktNbO5Ztav1r7RZva5ma01s5+GKqOINE+JcTH8ZXweebmtuO3vi3lz2fZG/fyaGsfbK3YwqndWk7id9oBQXmFMBR4Dnqtn/93AYufchWbWG/gzcLqZxQSenwlsAeaZ2b+ccytDmFVEmpmk+BimXDWE8ZPncNP0Rfy0cD+9s9Nom5ZA65QEdhaVsS6/hPUFJezcV0ZCXAxJcTEkxcdwYpdWDMypfyDewk17yC8qZ3S/dmH8E4VeyAqGc26mmeU2cEgf4P7AsavNLNfM2gJdgbXOuXUAZvY3YAyggiEijSolIZap1wzlyilz+dW/V9V7XFpiLBXVNZRVfj1KfMyA9vz0nN60S0/6r+PfXP4V8TE+RvVqOs1R4G0fxhLgImCWmQ0FOgMdgQ5A7aGYW4ATwx9PRJqDtMQ4Zkw8ic27S9mxr4wdReUUFJWTlZpAl8wWdMlsQYsE/1+VNTWOorIqJs9ax5Mz1/HOih38cGQ3Jo7sRlyMv4XfOcdby79iRI9MUhPjvPyjNTovC8YDwCNmthhYBiwCqoC67j9z9X2ImV0PXA+Qk5MTgpgi0tTF+IzczBbkZrZo8Difz0hPjuP2s3rx3bxO3P/mKh569wt2FpXzywv83bDLt+5ja+F+bjmjRziih5Vnt9U65/Y55652zg0AxgNZwHr8VxSdah3aEdjWwOdMcs7lOefysrKa1uWfiESuTq2SefyKwfzg1K48/9lG/j5vE+C/OyrGZ5x5XNO5nfYAz64wzCwDKHXOVQDXAjOdc/vMbB7Qw8y6AFuBy4Dve5VTRKQhd43uzcrt+/j5P1bQo20qby7/imFdW9GyRbzX0RpdKG+rnQ7MBnqZ2RYzm2BmE81sYuCQ44AVZrYaOAe4BcA5VwX8CHgbWAW86JxbEaqcIiLHIsZn/OnygWSnJ3L1M/NYl1/S5O6OOiCUd0ldfpj9s4E6G/mcc28Ab4Qil4hIY8tIjmfS+MFc+OdPMYOzm9Do7to00ltEpBH0zk5j8lV5rN1ZTJu0RK/jhIQKhohIIzmpWyYndWsaU5nXRZMPiohIUFQwREQkKCoYIiISFBUMEREJigqGiIgERQVDRESCooIhIiJBUcEQEZGgmHP1zhwedcxsL7Cmjl3pwN4gXx94Xte2TKDgCGMdeq5g99e1va5M9T0/lswN5Qo2X7Rkrmt7NH4/gslc+7m+H8Hvb+rfjx7OufSg0jjnmswDmBTM9oZeH3hez7b5jZXpSDPXl+lw+Y8m89HmjsbMTeX7EUxmr3/W+n5E/vfjcI+m1iT1WpDbG3r9WgPbGjPT4fbXtb2+TIfLfzSOJnc0Zq5rezR+P4LJXPu5vh/B729O348GNakmqVAzs/nOuTyvcxwJZQ6faMytzOETrblra2pXGKE2yesAR0GZwycacytz+ERr7oN0hSEiIkHRFYaIiASl2RYMM5tiZjvNbPlRvHewmS0zs7Vm9qiZWa19N5nZ52a2wsx+F+mZzex/zWyrmS0OPL4d6Zlr7b/TzJyZNfoCBCH6Wf/SzJYGfs7vmFn7KMj8ezNbHcj9qpllREHm7wZ+/2rMrNH6DI4laz2fd6WZrQk8rqy1vcHvvaeO5va0pvAATgUGAcuP4r1zgeGAAW8C5wS2jwLeAxICr9tEQeb/Be6Mpp9zYF8n/Ou+bwQyoyE3kFbrmJuBJ6Mg81lAbOD5b4HfRkHm44BewIdAntdZAzlyD9nWClgX+G/LwPOWDf25IuHRbK8wnHMzgd21t5lZNzN7y8wWmNnHZtb70PeZWTv8v/iznf//7nPABYHdNwAPOOfKA+fYGQWZQyqEmR8G7gJC0gkXitzOuX21Dm3R2NlDlPkd51xV4NDPgI5RkHmVc+7zxsx5LFnrcTbwrnNut3NuD/AuMNrL39VgNNuCUY9JwE3OucHAncDjdRzTAdhS6/WWwDaAnsAIM5tjZh+Z2ZCQpvU71swAPwo0OUwxs5ahi3rQMWU2s/OBrc65JaEOeohj/lmb2a/NbDNwBfCLEGY9oDG+Hwdcg/9fvKHWmJlDLZisdekAbK71+kD+SPlz1UlregeYWQpwEvBSrSbDhLoOrWPbgX8pxuK/vBwGDAFeNLOugX8pNLpGyvwE8MvA618CD+H/iyEkjjWzmSUD9+BvKgmbRvpZ45y7B7jHzH4G/Ai4t5Gjfh2kkTIHPuseoAp4oTEz/leQRswcag1lNbOrgVsC27oDb5hZBbDeOXch9ef3/M/VEBWMr/mAQufcgNobzSwGWBB4+S/8f8HWvizvCGwLPN8CvBIoEHPNrAb//DH5kZrZObej1vv+ArweoqwHHGvmbkAXYEngl7QjsNDMhjrnvorg3If6K/BvQlgwaKTMgQ7Z84DTQ/WPn1oa++ccSnVmBXDOPQM8A2BmHwJXOec21DpkCzCy1uuO+Ps6tuD9n6t+XneiePkAcqnVgQV8Cnw38NyAE+p53zz8VxEHOqW+Hdg+Ebgv8Lwn/ktOi/DM7Wodcxvwt0j/OR9yzAZC0Okdop91j1rH3ATMiILMo4GVQFYofsah/H7QyJ3eR5uV+ju91+NvkWgZeN4q2O+9Vw/PA3j2B4fpwHagEn9Vn4D/X65vAUsCvyS/qOe9ecBy4EvgMb4eABkPTAvsWwh8KwoyPw8sA5bi/5dbu0jPfMgxGwjNXVKh+Fm/HNi+FP/8PR2iIPNa/P/wWRx4NPadXaHIfGHgs8qBHcDbXmaljoIR2H5N4Oe7Frj6SL73Xj000ltERIKiu6RERCQoKhgiIhIUFQwREQmKCoaIiARFBUNERIKigiFNmpkVh/l8T5tZn0b6rGrzz2y73MxeO9xMsWaWYWY/bIxzi9RFt9VKk2Zmxc65lEb8vFj39WR8IVU7u5k9C3zhnPt1A8fnAq875/qFI580P7rCkGbHzLLM7GUzmxd4nBzYPtTMPjWzRYH/9gpsv8rMXjKz14B3zGykmX1oZjPMv1bECwfWLAhszws8Lw5MNrjEzD4zs7aB7d0Cr+eZ2X1BXgXN5uvJF1PM7H0zW2j+dRPGBI55AOgWuCr5feDYHwfOs9TM/q8Rf4zSDKlgSHP0CPCwc24IcDHwdGD7auBU59xA/DPJ/qbWe4YDVzrnvhV4PRC4FegDdAVOruM8LYDPnHMnADOB62qd/5HA+Q87T1BgHqXT8Y/EBygDLnTODcK/BstDgYL1U+BL59wA59yPzewsoAcwFBgADDazUw93PpH6aPJBaY7OAPrUmmE0zcxSgXTgWTPrgX+G0Lha73nXOVd7LYS5zrktAGa2GP8cQ7MOOU8FX0/muAA4M/B8OF+vcfBX4MF6cibV+uwF+NdMAP8cQ78J/OVfg//Ko20d7z8r8FgUeJ2Cv4DMrOd8Ig1SwZDmyAcMd87tr73RzP4EfOCcuzDQH/Bhrd0lh3xGea3n1dT9u1Tpvu4krO+Yhux3zg0ws3T8hedG4FH8a2lkAYOdc5VmtgFIrOP9BtzvnHvqCM8rUic1SUlz9A7+tSgAMLMD01OnA1sDz68K4fk/w98UBnDZ4Q52zu3Fv6TrnWYWhz/nzkCxGAV0DhxaBKTWeuvbwDWBdRswsw5m1qaR/gzSDKlgSFOXbGZbaj1ux/+Xb16gI3gl/mnpAX4H3G9mnwAxIcx0K3C7mc0F2gF7D/cG59wi/DOiXoZ/EaM8M5uP/2pjdeCYXcAngdtwf++cewd/k9dsM1sGzOCbBUXkiOi2WpEwC6wauN8558zsMuBy59yYw71PxGvqwxAJv8HAY4E7mwoJ4ZK4Io1JVxgiIhIU9WGIiEhQVDBERCQoKhgiIhIUFQwREQmKCoaIiARFBUNERILy/38et8Y6JLqeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>LMAEMaskedLoss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.390631</td>\n",
       "      <td>-1.246222</td>\n",
       "      <td>-1.246222</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-1.396077</td>\n",
       "      <td>-1.241531</td>\n",
       "      <td>-1.241531</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.395480</td>\n",
       "      <td>-1.237858</td>\n",
       "      <td>-1.237858</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-1.400086</td>\n",
       "      <td>-1.240585</td>\n",
       "      <td>-1.240585</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.393335</td>\n",
       "      <td>-1.244123</td>\n",
       "      <td>-1.244123</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-1.395661</td>\n",
       "      <td>-1.235244</td>\n",
       "      <td>-1.235244</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-1.393739</td>\n",
       "      <td>-1.233381</td>\n",
       "      <td>-1.233381</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>-1.390243</td>\n",
       "      <td>-1.240160</td>\n",
       "      <td>-1.240160</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>-1.385368</td>\n",
       "      <td>-1.220728</td>\n",
       "      <td>-1.220728</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>-1.372607</td>\n",
       "      <td>-1.225624</td>\n",
       "      <td>-1.225624</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>-1.372943</td>\n",
       "      <td>-1.222421</td>\n",
       "      <td>-1.222421</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>-1.370975</td>\n",
       "      <td>-1.222021</td>\n",
       "      <td>-1.222021</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>-1.369579</td>\n",
       "      <td>-1.224915</td>\n",
       "      <td>-1.224915</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>-1.363897</td>\n",
       "      <td>-1.207962</td>\n",
       "      <td>-1.207962</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>-1.358741</td>\n",
       "      <td>-1.192885</td>\n",
       "      <td>-1.192885</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>-1.353899</td>\n",
       "      <td>-1.185645</td>\n",
       "      <td>-1.185645</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>-1.345762</td>\n",
       "      <td>-1.191853</td>\n",
       "      <td>-1.191853</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>-1.339950</td>\n",
       "      <td>-1.184417</td>\n",
       "      <td>-1.184417</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>-1.340806</td>\n",
       "      <td>-1.170244</td>\n",
       "      <td>-1.170244</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>-1.334356</td>\n",
       "      <td>-1.166012</td>\n",
       "      <td>-1.166012</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>-1.314642</td>\n",
       "      <td>-1.111788</td>\n",
       "      <td>-1.111788</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>-1.315975</td>\n",
       "      <td>-1.151489</td>\n",
       "      <td>-1.151490</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>-1.309791</td>\n",
       "      <td>-1.145183</td>\n",
       "      <td>-1.145183</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>-1.295047</td>\n",
       "      <td>-1.136829</td>\n",
       "      <td>-1.136829</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>-1.291730</td>\n",
       "      <td>-1.122960</td>\n",
       "      <td>-1.122960</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>-1.283150</td>\n",
       "      <td>-1.107215</td>\n",
       "      <td>-1.107215</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>-1.266657</td>\n",
       "      <td>-1.113076</td>\n",
       "      <td>-1.113076</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>-1.269050</td>\n",
       "      <td>-1.111474</td>\n",
       "      <td>-1.111474</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>-1.255582</td>\n",
       "      <td>-1.075394</td>\n",
       "      <td>-1.075394</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>-1.249034</td>\n",
       "      <td>-1.041670</td>\n",
       "      <td>-1.041670</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>-1.235677</td>\n",
       "      <td>-1.043184</td>\n",
       "      <td>-1.043184</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>-1.228193</td>\n",
       "      <td>-1.020825</td>\n",
       "      <td>-1.020825</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>-1.213080</td>\n",
       "      <td>-0.993554</td>\n",
       "      <td>-0.993554</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>-1.188438</td>\n",
       "      <td>-0.972391</td>\n",
       "      <td>-0.972391</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>-1.181398</td>\n",
       "      <td>-0.987755</td>\n",
       "      <td>-0.987755</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>-1.177038</td>\n",
       "      <td>-1.002870</td>\n",
       "      <td>-1.002870</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>-1.169333</td>\n",
       "      <td>-0.999099</td>\n",
       "      <td>-0.999099</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>-1.163194</td>\n",
       "      <td>-0.841439</td>\n",
       "      <td>-0.841439</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>-1.149408</td>\n",
       "      <td>-0.920468</td>\n",
       "      <td>-0.920468</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>-1.134487</td>\n",
       "      <td>-0.925094</td>\n",
       "      <td>-0.925094</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>-1.109808</td>\n",
       "      <td>-0.872466</td>\n",
       "      <td>-0.872466</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>-1.121098</td>\n",
       "      <td>-0.938357</td>\n",
       "      <td>-0.938357</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>-1.100577</td>\n",
       "      <td>-0.821602</td>\n",
       "      <td>-0.821602</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>-1.081541</td>\n",
       "      <td>-0.797796</td>\n",
       "      <td>-0.797796</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>-1.085555</td>\n",
       "      <td>-0.605188</td>\n",
       "      <td>-0.605188</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>-1.062020</td>\n",
       "      <td>-0.811276</td>\n",
       "      <td>-0.811275</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>-1.020358</td>\n",
       "      <td>-0.785511</td>\n",
       "      <td>-0.785511</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>-1.044502</td>\n",
       "      <td>-0.772810</td>\n",
       "      <td>-0.772810</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>-1.029186</td>\n",
       "      <td>-0.734354</td>\n",
       "      <td>-0.734354</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>-0.996683</td>\n",
       "      <td>-0.731432</td>\n",
       "      <td>-0.731432</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>-0.989804</td>\n",
       "      <td>-0.673627</td>\n",
       "      <td>-0.673627</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>-0.999958</td>\n",
       "      <td>-0.761406</td>\n",
       "      <td>-0.761406</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>-0.984783</td>\n",
       "      <td>-0.676094</td>\n",
       "      <td>-0.676094</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>-0.989585</td>\n",
       "      <td>-0.585857</td>\n",
       "      <td>-0.585857</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>-0.943026</td>\n",
       "      <td>-0.711416</td>\n",
       "      <td>-0.711416</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>-0.962188</td>\n",
       "      <td>-0.469965</td>\n",
       "      <td>-0.469965</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>-0.945942</td>\n",
       "      <td>-0.609132</td>\n",
       "      <td>-0.609132</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>-0.933450</td>\n",
       "      <td>-0.630477</td>\n",
       "      <td>-0.630477</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>-0.916831</td>\n",
       "      <td>-0.553820</td>\n",
       "      <td>-0.553820</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>-0.937195</td>\n",
       "      <td>-0.117981</td>\n",
       "      <td>-0.117981</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>-0.925673</td>\n",
       "      <td>-0.377272</td>\n",
       "      <td>-0.377272</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>-0.883636</td>\n",
       "      <td>-0.642080</td>\n",
       "      <td>-0.642080</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>-0.858666</td>\n",
       "      <td>-0.594485</td>\n",
       "      <td>-0.594485</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>-0.872237</td>\n",
       "      <td>-0.481101</td>\n",
       "      <td>-0.481101</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>-0.880905</td>\n",
       "      <td>-0.480087</td>\n",
       "      <td>-0.480087</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>-0.857729</td>\n",
       "      <td>-0.439302</td>\n",
       "      <td>-0.439302</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>-0.855875</td>\n",
       "      <td>-0.451152</td>\n",
       "      <td>-0.451152</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>-0.859088</td>\n",
       "      <td>-0.543052</td>\n",
       "      <td>-0.543052</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>-0.815705</td>\n",
       "      <td>-0.192366</td>\n",
       "      <td>-0.192366</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>-0.857778</td>\n",
       "      <td>-0.489369</td>\n",
       "      <td>-0.489369</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>-0.844375</td>\n",
       "      <td>-0.523306</td>\n",
       "      <td>-0.523306</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>-0.818743</td>\n",
       "      <td>-0.338320</td>\n",
       "      <td>-0.338320</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>-0.837895</td>\n",
       "      <td>-0.511022</td>\n",
       "      <td>-0.511022</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>-0.805691</td>\n",
       "      <td>-0.430829</td>\n",
       "      <td>-0.430829</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>-0.817942</td>\n",
       "      <td>-0.533782</td>\n",
       "      <td>-0.533782</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>-0.848497</td>\n",
       "      <td>-0.595113</td>\n",
       "      <td>-0.595113</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>-0.795482</td>\n",
       "      <td>-0.384944</td>\n",
       "      <td>-0.384944</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>-0.834458</td>\n",
       "      <td>-0.359913</td>\n",
       "      <td>-0.359913</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>-0.847676</td>\n",
       "      <td>-0.510999</td>\n",
       "      <td>-0.510999</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>-0.817747</td>\n",
       "      <td>-0.468197</td>\n",
       "      <td>-0.468197</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>-0.800768</td>\n",
       "      <td>-0.538760</td>\n",
       "      <td>-0.538760</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>-0.828313</td>\n",
       "      <td>-0.280839</td>\n",
       "      <td>-0.280839</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>-0.830497</td>\n",
       "      <td>-0.684210</td>\n",
       "      <td>-0.684210</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>-0.831652</td>\n",
       "      <td>-0.429593</td>\n",
       "      <td>-0.429593</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>-0.822609</td>\n",
       "      <td>-0.295292</td>\n",
       "      <td>-0.295292</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>-0.817765</td>\n",
       "      <td>-0.202098</td>\n",
       "      <td>-0.202098</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>-0.799626</td>\n",
       "      <td>-0.446701</td>\n",
       "      <td>-0.446701</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>-0.803235</td>\n",
       "      <td>-0.592102</td>\n",
       "      <td>-0.592102</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>-0.812373</td>\n",
       "      <td>-0.589706</td>\n",
       "      <td>-0.589706</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>-0.847737</td>\n",
       "      <td>-0.539472</td>\n",
       "      <td>-0.539472</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>-0.835431</td>\n",
       "      <td>-0.390360</td>\n",
       "      <td>-0.390360</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>-0.804032</td>\n",
       "      <td>-0.497936</td>\n",
       "      <td>-0.497936</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>-0.834603</td>\n",
       "      <td>-0.500392</td>\n",
       "      <td>-0.500392</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>-0.857726</td>\n",
       "      <td>-0.606007</td>\n",
       "      <td>-0.606007</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>-0.823219</td>\n",
       "      <td>-0.536087</td>\n",
       "      <td>-0.536087</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>-0.843488</td>\n",
       "      <td>-0.445768</td>\n",
       "      <td>-0.445768</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>-0.829724</td>\n",
       "      <td>-0.580319</td>\n",
       "      <td>-0.580319</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>-0.843613</td>\n",
       "      <td>-0.589387</td>\n",
       "      <td>-0.589387</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>-0.831375</td>\n",
       "      <td>-0.638395</td>\n",
       "      <td>-0.638395</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>-0.838242</td>\n",
       "      <td>-0.605558</td>\n",
       "      <td>-0.605558</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>-0.882884</td>\n",
       "      <td>-0.659389</td>\n",
       "      <td>-0.659389</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>-0.841633</td>\n",
       "      <td>-0.495714</td>\n",
       "      <td>-0.495714</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>-0.879109</td>\n",
       "      <td>-0.487781</td>\n",
       "      <td>-0.487781</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>-0.850053</td>\n",
       "      <td>-0.504515</td>\n",
       "      <td>-0.504515</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>-0.875419</td>\n",
       "      <td>-0.479145</td>\n",
       "      <td>-0.479145</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>-0.824308</td>\n",
       "      <td>-0.552861</td>\n",
       "      <td>-0.552861</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>-0.876714</td>\n",
       "      <td>-0.535565</td>\n",
       "      <td>-0.535565</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>-0.841603</td>\n",
       "      <td>-0.642896</td>\n",
       "      <td>-0.642896</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>-0.859983</td>\n",
       "      <td>-0.534114</td>\n",
       "      <td>-0.534114</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>-0.861113</td>\n",
       "      <td>-0.619043</td>\n",
       "      <td>-0.619043</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>-0.862343</td>\n",
       "      <td>-0.407344</td>\n",
       "      <td>-0.407344</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>-0.903016</td>\n",
       "      <td>-0.576070</td>\n",
       "      <td>-0.576070</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>-0.891358</td>\n",
       "      <td>-0.459463</td>\n",
       "      <td>-0.459463</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>-0.880138</td>\n",
       "      <td>-0.512758</td>\n",
       "      <td>-0.512758</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>-0.878477</td>\n",
       "      <td>-0.238877</td>\n",
       "      <td>-0.238877</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>-0.884859</td>\n",
       "      <td>-0.663973</td>\n",
       "      <td>-0.663973</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>-0.874242</td>\n",
       "      <td>-0.520110</td>\n",
       "      <td>-0.520110</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>-0.866021</td>\n",
       "      <td>-0.592760</td>\n",
       "      <td>-0.592760</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>-0.888678</td>\n",
       "      <td>-0.538505</td>\n",
       "      <td>-0.538505</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>-0.871343</td>\n",
       "      <td>-0.582623</td>\n",
       "      <td>-0.582623</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>-0.884588</td>\n",
       "      <td>-0.595489</td>\n",
       "      <td>-0.595489</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>-0.901905</td>\n",
       "      <td>-0.623755</td>\n",
       "      <td>-0.623755</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>-0.929955</td>\n",
       "      <td>-0.670332</td>\n",
       "      <td>-0.670332</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>-0.882710</td>\n",
       "      <td>-0.549345</td>\n",
       "      <td>-0.549345</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>-0.910368</td>\n",
       "      <td>-0.712315</td>\n",
       "      <td>-0.712315</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>-0.889355</td>\n",
       "      <td>-0.693551</td>\n",
       "      <td>-0.693550</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>-0.920083</td>\n",
       "      <td>-0.437684</td>\n",
       "      <td>-0.437684</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>-0.934503</td>\n",
       "      <td>-0.577295</td>\n",
       "      <td>-0.577295</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>-0.930869</td>\n",
       "      <td>-0.648314</td>\n",
       "      <td>-0.648314</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>-0.927370</td>\n",
       "      <td>-0.588251</td>\n",
       "      <td>-0.588251</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>-0.908876</td>\n",
       "      <td>-0.468028</td>\n",
       "      <td>-0.468028</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>-0.919742</td>\n",
       "      <td>-0.537106</td>\n",
       "      <td>-0.537106</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>-0.910791</td>\n",
       "      <td>-0.498394</td>\n",
       "      <td>-0.498394</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>-0.915357</td>\n",
       "      <td>-0.574421</td>\n",
       "      <td>-0.574421</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>-0.937023</td>\n",
       "      <td>-0.678185</td>\n",
       "      <td>-0.678185</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>-0.923203</td>\n",
       "      <td>-0.528188</td>\n",
       "      <td>-0.528188</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>-0.946790</td>\n",
       "      <td>-0.729697</td>\n",
       "      <td>-0.729697</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>-0.933438</td>\n",
       "      <td>-0.671491</td>\n",
       "      <td>-0.671491</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>-0.946365</td>\n",
       "      <td>-0.692070</td>\n",
       "      <td>-0.692070</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>-0.948740</td>\n",
       "      <td>-0.536551</td>\n",
       "      <td>-0.536551</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>-0.936409</td>\n",
       "      <td>-0.571698</td>\n",
       "      <td>-0.571698</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>-0.968683</td>\n",
       "      <td>-0.703692</td>\n",
       "      <td>-0.703692</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>-0.963636</td>\n",
       "      <td>-0.759026</td>\n",
       "      <td>-0.759026</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>-0.971695</td>\n",
       "      <td>-0.721391</td>\n",
       "      <td>-0.721391</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>-0.953500</td>\n",
       "      <td>-0.661847</td>\n",
       "      <td>-0.661847</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>-0.969493</td>\n",
       "      <td>-0.651938</td>\n",
       "      <td>-0.651938</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>-0.976358</td>\n",
       "      <td>-0.727764</td>\n",
       "      <td>-0.727764</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>-0.963311</td>\n",
       "      <td>-0.689547</td>\n",
       "      <td>-0.689547</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>-0.979291</td>\n",
       "      <td>-0.697413</td>\n",
       "      <td>-0.697413</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>-0.999937</td>\n",
       "      <td>-0.630030</td>\n",
       "      <td>-0.630030</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>-0.967975</td>\n",
       "      <td>-0.664115</td>\n",
       "      <td>-0.664115</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>-0.987764</td>\n",
       "      <td>-0.704949</td>\n",
       "      <td>-0.704949</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>-0.983692</td>\n",
       "      <td>-0.788233</td>\n",
       "      <td>-0.788233</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>-1.014381</td>\n",
       "      <td>-0.692964</td>\n",
       "      <td>-0.692964</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>-1.002010</td>\n",
       "      <td>-0.810324</td>\n",
       "      <td>-0.810325</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>-1.015486</td>\n",
       "      <td>-0.829064</td>\n",
       "      <td>-0.829064</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>-1.006895</td>\n",
       "      <td>-0.673708</td>\n",
       "      <td>-0.673708</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>-1.021387</td>\n",
       "      <td>-0.677835</td>\n",
       "      <td>-0.677834</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>-1.030362</td>\n",
       "      <td>-0.854356</td>\n",
       "      <td>-0.854356</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>-1.028944</td>\n",
       "      <td>-0.744081</td>\n",
       "      <td>-0.744081</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>-1.024286</td>\n",
       "      <td>-0.842163</td>\n",
       "      <td>-0.842163</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>-1.014993</td>\n",
       "      <td>-0.872818</td>\n",
       "      <td>-0.872818</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>-1.031788</td>\n",
       "      <td>-0.774904</td>\n",
       "      <td>-0.774904</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>-1.018777</td>\n",
       "      <td>-0.817267</td>\n",
       "      <td>-0.817267</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>-1.035188</td>\n",
       "      <td>-0.878926</td>\n",
       "      <td>-0.878926</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>-1.035341</td>\n",
       "      <td>-0.812710</td>\n",
       "      <td>-0.812710</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>-1.029732</td>\n",
       "      <td>-0.889693</td>\n",
       "      <td>-0.889693</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>-1.041948</td>\n",
       "      <td>-0.785560</td>\n",
       "      <td>-0.785560</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>-1.060125</td>\n",
       "      <td>-0.851516</td>\n",
       "      <td>-0.851516</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>-1.057892</td>\n",
       "      <td>-0.877096</td>\n",
       "      <td>-0.877096</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>-1.054254</td>\n",
       "      <td>-0.889758</td>\n",
       "      <td>-0.889758</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>-1.059980</td>\n",
       "      <td>-0.911598</td>\n",
       "      <td>-0.911598</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>-1.066947</td>\n",
       "      <td>-0.883306</td>\n",
       "      <td>-0.883306</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>-1.069959</td>\n",
       "      <td>-0.946740</td>\n",
       "      <td>-0.946740</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>-1.073405</td>\n",
       "      <td>-0.924299</td>\n",
       "      <td>-0.924299</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>-1.093484</td>\n",
       "      <td>-0.808360</td>\n",
       "      <td>-0.808360</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>-1.074922</td>\n",
       "      <td>-0.854155</td>\n",
       "      <td>-0.854155</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>-1.087756</td>\n",
       "      <td>-0.779970</td>\n",
       "      <td>-0.779970</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>-1.094741</td>\n",
       "      <td>-0.873830</td>\n",
       "      <td>-0.873830</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>-1.092490</td>\n",
       "      <td>-0.899428</td>\n",
       "      <td>-0.899428</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>-1.096436</td>\n",
       "      <td>-0.989025</td>\n",
       "      <td>-0.989025</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>-1.080173</td>\n",
       "      <td>-0.890689</td>\n",
       "      <td>-0.890689</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>-1.101410</td>\n",
       "      <td>-0.861237</td>\n",
       "      <td>-0.861237</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>-1.111135</td>\n",
       "      <td>-0.952288</td>\n",
       "      <td>-0.952288</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>-1.124392</td>\n",
       "      <td>-0.873539</td>\n",
       "      <td>-0.873539</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>-1.127837</td>\n",
       "      <td>-0.814752</td>\n",
       "      <td>-0.814752</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>-1.137782</td>\n",
       "      <td>-0.929117</td>\n",
       "      <td>-0.929117</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>-1.125654</td>\n",
       "      <td>-0.937828</td>\n",
       "      <td>-0.937828</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>-1.134328</td>\n",
       "      <td>-0.908470</td>\n",
       "      <td>-0.908470</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>-1.126965</td>\n",
       "      <td>-0.941583</td>\n",
       "      <td>-0.941583</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>-1.141407</td>\n",
       "      <td>-0.958460</td>\n",
       "      <td>-0.958460</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>-1.138606</td>\n",
       "      <td>-0.940145</td>\n",
       "      <td>-0.940145</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>-1.135311</td>\n",
       "      <td>-0.951012</td>\n",
       "      <td>-0.951012</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>-1.150707</td>\n",
       "      <td>-0.947943</td>\n",
       "      <td>-0.947943</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>-1.162120</td>\n",
       "      <td>-0.955124</td>\n",
       "      <td>-0.955124</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>-1.160441</td>\n",
       "      <td>-0.960596</td>\n",
       "      <td>-0.960596</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>-1.172427</td>\n",
       "      <td>-1.026141</td>\n",
       "      <td>-1.026141</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>-1.173636</td>\n",
       "      <td>-1.044837</td>\n",
       "      <td>-1.044837</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>-1.181728</td>\n",
       "      <td>-0.972082</td>\n",
       "      <td>-0.972082</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>-1.173870</td>\n",
       "      <td>-1.004642</td>\n",
       "      <td>-1.004642</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>-1.190152</td>\n",
       "      <td>-0.957854</td>\n",
       "      <td>-0.957854</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>-1.185586</td>\n",
       "      <td>-0.953434</td>\n",
       "      <td>-0.953434</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>-1.186624</td>\n",
       "      <td>-1.011902</td>\n",
       "      <td>-1.011902</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>-1.198920</td>\n",
       "      <td>-1.005392</td>\n",
       "      <td>-1.005392</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>-1.200688</td>\n",
       "      <td>-0.957334</td>\n",
       "      <td>-0.957334</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>-1.190788</td>\n",
       "      <td>-1.030042</td>\n",
       "      <td>-1.030042</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>-1.196594</td>\n",
       "      <td>-1.000369</td>\n",
       "      <td>-1.000369</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>-1.211035</td>\n",
       "      <td>-1.061931</td>\n",
       "      <td>-1.061931</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>-1.217520</td>\n",
       "      <td>-1.037061</td>\n",
       "      <td>-1.037061</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>-1.224060</td>\n",
       "      <td>-0.964660</td>\n",
       "      <td>-0.964660</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>-1.225404</td>\n",
       "      <td>-1.027399</td>\n",
       "      <td>-1.027399</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>-1.233687</td>\n",
       "      <td>-1.067638</td>\n",
       "      <td>-1.067638</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>-1.238354</td>\n",
       "      <td>-1.059140</td>\n",
       "      <td>-1.059141</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>-1.247609</td>\n",
       "      <td>-1.102333</td>\n",
       "      <td>-1.102333</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>-1.240485</td>\n",
       "      <td>-1.064075</td>\n",
       "      <td>-1.064075</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>-1.244278</td>\n",
       "      <td>-1.089079</td>\n",
       "      <td>-1.089079</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>-1.246724</td>\n",
       "      <td>-1.109149</td>\n",
       "      <td>-1.109149</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>-1.256288</td>\n",
       "      <td>-1.093474</td>\n",
       "      <td>-1.093474</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>-1.262077</td>\n",
       "      <td>-1.107033</td>\n",
       "      <td>-1.107033</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>-1.264398</td>\n",
       "      <td>-1.120729</td>\n",
       "      <td>-1.120729</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>-1.275297</td>\n",
       "      <td>-1.113801</td>\n",
       "      <td>-1.113801</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>-1.282192</td>\n",
       "      <td>-1.065645</td>\n",
       "      <td>-1.065645</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>-1.283944</td>\n",
       "      <td>-1.150882</td>\n",
       "      <td>-1.150882</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>-1.289246</td>\n",
       "      <td>-1.111702</td>\n",
       "      <td>-1.111702</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>-1.290599</td>\n",
       "      <td>-1.097308</td>\n",
       "      <td>-1.097308</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>-1.285277</td>\n",
       "      <td>-1.113573</td>\n",
       "      <td>-1.113573</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>-1.292233</td>\n",
       "      <td>-1.137647</td>\n",
       "      <td>-1.137647</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>-1.302197</td>\n",
       "      <td>-1.147189</td>\n",
       "      <td>-1.147189</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>-1.303555</td>\n",
       "      <td>-1.184339</td>\n",
       "      <td>-1.184339</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>-1.313173</td>\n",
       "      <td>-1.166787</td>\n",
       "      <td>-1.166787</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>-1.318061</td>\n",
       "      <td>-1.145590</td>\n",
       "      <td>-1.145589</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>-1.322956</td>\n",
       "      <td>-1.165551</td>\n",
       "      <td>-1.165551</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>-1.318032</td>\n",
       "      <td>-1.179599</td>\n",
       "      <td>-1.179599</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>-1.322922</td>\n",
       "      <td>-1.167860</td>\n",
       "      <td>-1.167860</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>-1.330418</td>\n",
       "      <td>-1.136250</td>\n",
       "      <td>-1.136250</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>-1.339560</td>\n",
       "      <td>-1.164241</td>\n",
       "      <td>-1.164241</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>-1.346993</td>\n",
       "      <td>-1.185267</td>\n",
       "      <td>-1.185268</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>-1.335166</td>\n",
       "      <td>-1.183508</td>\n",
       "      <td>-1.183508</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>-1.344082</td>\n",
       "      <td>-1.166101</td>\n",
       "      <td>-1.166100</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>-1.350620</td>\n",
       "      <td>-1.192501</td>\n",
       "      <td>-1.192501</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>-1.363678</td>\n",
       "      <td>-1.223811</td>\n",
       "      <td>-1.223811</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>-1.365599</td>\n",
       "      <td>-1.230270</td>\n",
       "      <td>-1.230270</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>-1.369643</td>\n",
       "      <td>-1.185640</td>\n",
       "      <td>-1.185640</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>-1.380033</td>\n",
       "      <td>-1.212334</td>\n",
       "      <td>-1.212334</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>-1.376735</td>\n",
       "      <td>-1.216450</td>\n",
       "      <td>-1.216450</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>-1.388158</td>\n",
       "      <td>-1.231446</td>\n",
       "      <td>-1.231446</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>-1.391737</td>\n",
       "      <td>-1.219583</td>\n",
       "      <td>-1.219583</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>-1.399181</td>\n",
       "      <td>-1.244541</td>\n",
       "      <td>-1.244541</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>-1.401984</td>\n",
       "      <td>-1.248877</td>\n",
       "      <td>-1.248877</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>-1.404026</td>\n",
       "      <td>-1.257912</td>\n",
       "      <td>-1.257913</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>-1.401283</td>\n",
       "      <td>-1.251236</td>\n",
       "      <td>-1.251236</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>-1.413232</td>\n",
       "      <td>-1.263094</td>\n",
       "      <td>-1.263094</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>-1.420928</td>\n",
       "      <td>-1.257152</td>\n",
       "      <td>-1.257152</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>-1.423600</td>\n",
       "      <td>-1.274775</td>\n",
       "      <td>-1.274775</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>-1.421353</td>\n",
       "      <td>-1.249506</td>\n",
       "      <td>-1.249506</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>-1.433409</td>\n",
       "      <td>-1.280964</td>\n",
       "      <td>-1.280964</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>-1.433217</td>\n",
       "      <td>-1.265696</td>\n",
       "      <td>-1.265696</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>-1.440597</td>\n",
       "      <td>-1.287683</td>\n",
       "      <td>-1.287683</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>-1.444616</td>\n",
       "      <td>-1.283576</td>\n",
       "      <td>-1.283576</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>-1.448563</td>\n",
       "      <td>-1.276565</td>\n",
       "      <td>-1.276565</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>-1.455486</td>\n",
       "      <td>-1.293569</td>\n",
       "      <td>-1.293569</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>-1.455053</td>\n",
       "      <td>-1.295769</td>\n",
       "      <td>-1.295769</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>-1.460586</td>\n",
       "      <td>-1.297666</td>\n",
       "      <td>-1.297666</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>-1.470040</td>\n",
       "      <td>-1.303251</td>\n",
       "      <td>-1.303251</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>-1.469079</td>\n",
       "      <td>-1.303850</td>\n",
       "      <td>-1.303850</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>-1.472152</td>\n",
       "      <td>-1.309412</td>\n",
       "      <td>-1.309412</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>-1.476970</td>\n",
       "      <td>-1.306273</td>\n",
       "      <td>-1.306273</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>-1.480558</td>\n",
       "      <td>-1.308084</td>\n",
       "      <td>-1.308084</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>-1.486501</td>\n",
       "      <td>-1.314606</td>\n",
       "      <td>-1.314606</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>-1.488518</td>\n",
       "      <td>-1.310645</td>\n",
       "      <td>-1.310645</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>-1.492784</td>\n",
       "      <td>-1.314411</td>\n",
       "      <td>-1.314411</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>-1.494954</td>\n",
       "      <td>-1.320563</td>\n",
       "      <td>-1.320564</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>-1.501274</td>\n",
       "      <td>-1.322054</td>\n",
       "      <td>-1.322054</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>-1.501110</td>\n",
       "      <td>-1.319180</td>\n",
       "      <td>-1.319180</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>-1.500166</td>\n",
       "      <td>-1.324970</td>\n",
       "      <td>-1.324970</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>-1.506570</td>\n",
       "      <td>-1.323807</td>\n",
       "      <td>-1.323807</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>-1.510769</td>\n",
       "      <td>-1.332985</td>\n",
       "      <td>-1.332985</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>-1.511097</td>\n",
       "      <td>-1.324955</td>\n",
       "      <td>-1.324955</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278</td>\n",
       "      <td>-1.514910</td>\n",
       "      <td>-1.330357</td>\n",
       "      <td>-1.330357</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>-1.518132</td>\n",
       "      <td>-1.334472</td>\n",
       "      <td>-1.334472</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>-1.518871</td>\n",
       "      <td>-1.329383</td>\n",
       "      <td>-1.329383</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>-1.521220</td>\n",
       "      <td>-1.332423</td>\n",
       "      <td>-1.332423</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>-1.524945</td>\n",
       "      <td>-1.338303</td>\n",
       "      <td>-1.338303</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>-1.527892</td>\n",
       "      <td>-1.339096</td>\n",
       "      <td>-1.339096</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>-1.528941</td>\n",
       "      <td>-1.337593</td>\n",
       "      <td>-1.337593</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>-1.530965</td>\n",
       "      <td>-1.341917</td>\n",
       "      <td>-1.341917</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>-1.533809</td>\n",
       "      <td>-1.338717</td>\n",
       "      <td>-1.338717</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>-1.534669</td>\n",
       "      <td>-1.340367</td>\n",
       "      <td>-1.340367</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>-1.538215</td>\n",
       "      <td>-1.341179</td>\n",
       "      <td>-1.341179</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>-1.537784</td>\n",
       "      <td>-1.341722</td>\n",
       "      <td>-1.341722</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>-1.539502</td>\n",
       "      <td>-1.341734</td>\n",
       "      <td>-1.341734</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>-1.540899</td>\n",
       "      <td>-1.340961</td>\n",
       "      <td>-1.340961</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>-1.542051</td>\n",
       "      <td>-1.342807</td>\n",
       "      <td>-1.342807</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>-1.544197</td>\n",
       "      <td>-1.342456</td>\n",
       "      <td>-1.342456</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>-1.545054</td>\n",
       "      <td>-1.341563</td>\n",
       "      <td>-1.341563</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>-1.544419</td>\n",
       "      <td>-1.343741</td>\n",
       "      <td>-1.343741</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>-1.545101</td>\n",
       "      <td>-1.343302</td>\n",
       "      <td>-1.343302</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>-1.545052</td>\n",
       "      <td>-1.344557</td>\n",
       "      <td>-1.344557</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>-1.544193</td>\n",
       "      <td>-1.346820</td>\n",
       "      <td>-1.346820</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>-1.545902</td>\n",
       "      <td>-1.344305</td>\n",
       "      <td>-1.344305</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(300, max_lr=2.5e-2)\n",
    "#learner.fit(20, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.add_test(ItemList(items=(MoleculeItem(i,*v) for i,v in enumerate(zip(xt_xyz,xt_a_hot,xt_type)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBunch;\n",
       "\n",
       "Train: LabelList (707619 items)\n",
       "x: ItemList\n",
       "0 5 atoms 4 couplings,1 5 atoms 3 couplings,2 5 atoms 2 couplings,3 5 atoms 1 couplings,4 4 atoms 3 couplings\n",
       "y: ScalarCouplingList\n",
       "4: 84.8076 * -11.2569 -11.2549 -11.2543,3: 84.8074 * -11.2542 -11.2548,2: 84.8093 * -11.2543,1: 84.8095,3: 32.6888 * -11.1867 -11.1757\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (78217 items)\n",
       "x: ItemList\n",
       "[tensor([[[ 2.2612e+00,  1.0621e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 4.0000e+00,  0.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[-1.0621e+00, -2.2612e+00, -3.3233e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  4.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[-1.0201e+00, -1.0100e+00, -3.6733e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-4.1775e-01, -1.8238e+00, -2.3635e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0147e-03,  9.9403e-03, -1.1182e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00, -1.0000e+00,  6.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2143e+00, -2.6623e+00, -3.2349e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-4.1250e+00, -3.1532e+00, -1.9880e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 2.3740e+00,  1.8268e+00,  1.1467e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[-2.1516e+00, -2.5995e+00, -3.1721e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-5.4036e+00, -4.4318e+00, -3.2665e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0703e+00,  5.2304e-01, -1.5706e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[ 2.0401e-02,  8.1824e-02,  1.8325e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-2.9596e+00, -1.8062e+00, -3.4983e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0859e+00,  1.0521e+00,  1.0215e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 1.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 7.0000e+00,  4.0000e+00,  0.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]]], device='cuda:0'), tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')],[tensor([[[ 2.2612e+00,  1.0621e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 4.0000e+00,  0.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[-1.0621e+00, -2.2612e+00, -3.3233e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  4.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[-1.0201e+00, -1.0100e+00, -3.6733e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-4.1775e-01, -1.8238e+00, -2.3635e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0147e-03,  9.9403e-03, -1.1182e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00, -1.0000e+00,  6.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2143e+00, -2.6623e+00, -3.2349e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-4.1250e+00, -3.1532e+00, -1.9880e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 2.3740e+00,  1.8268e+00,  1.1467e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[-2.1516e+00, -2.5995e+00, -3.1721e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-5.4036e+00, -4.4318e+00, -3.2665e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0703e+00,  5.2304e-01, -1.5706e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[ 2.0401e-02,  8.1824e-02,  1.8325e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-2.9596e+00, -1.8062e+00, -3.4983e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0859e+00,  1.0521e+00,  1.0215e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 1.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 7.0000e+00,  4.0000e+00,  0.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]]], device='cuda:0'), tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')],[tensor([[[ 2.2612e+00,  1.0621e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 4.0000e+00,  0.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[-1.0621e+00, -2.2612e+00, -3.3233e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  4.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[-1.0201e+00, -1.0100e+00, -3.6733e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-4.1775e-01, -1.8238e+00, -2.3635e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0147e-03,  9.9403e-03, -1.1182e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00, -1.0000e+00,  6.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2143e+00, -2.6623e+00, -3.2349e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-4.1250e+00, -3.1532e+00, -1.9880e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 2.3740e+00,  1.8268e+00,  1.1467e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[-2.1516e+00, -2.5995e+00, -3.1721e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-5.4036e+00, -4.4318e+00, -3.2665e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0703e+00,  5.2304e-01, -1.5706e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[ 2.0401e-02,  8.1824e-02,  1.8325e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-2.9596e+00, -1.8062e+00, -3.4983e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0859e+00,  1.0521e+00,  1.0215e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 1.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 7.0000e+00,  4.0000e+00,  0.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]]], device='cuda:0'), tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')],[tensor([[[ 2.2612e+00,  1.0621e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 4.0000e+00,  0.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[-1.0621e+00, -2.2612e+00, -3.3233e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  4.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[-1.0201e+00, -1.0100e+00, -3.6733e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-4.1775e-01, -1.8238e+00, -2.3635e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0147e-03,  9.9403e-03, -1.1182e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00, -1.0000e+00,  6.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2143e+00, -2.6623e+00, -3.2349e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-4.1250e+00, -3.1532e+00, -1.9880e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 2.3740e+00,  1.8268e+00,  1.1467e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[-2.1516e+00, -2.5995e+00, -3.1721e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-5.4036e+00, -4.4318e+00, -3.2665e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0703e+00,  5.2304e-01, -1.5706e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[ 2.0401e-02,  8.1824e-02,  1.8325e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-2.9596e+00, -1.8062e+00, -3.4983e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0859e+00,  1.0521e+00,  1.0215e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 1.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 7.0000e+00,  4.0000e+00,  0.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]]], device='cuda:0'), tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')],[tensor([[[ 2.2612e+00,  1.0621e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 4.0000e+00,  0.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[-1.0621e+00, -2.2612e+00, -3.3233e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  4.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[-1.0201e+00, -1.0100e+00, -3.6733e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-4.1775e-01, -1.8238e+00, -2.3635e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0147e-03,  9.9403e-03, -1.1182e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00, -1.0000e+00,  6.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2143e+00, -2.6623e+00, -3.2349e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-4.1250e+00, -3.1532e+00, -1.9880e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 2.3740e+00,  1.8268e+00,  1.1467e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[-2.1516e+00, -2.5995e+00, -3.1721e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-5.4036e+00, -4.4318e+00, -3.2665e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0703e+00,  5.2304e-01, -1.5706e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "        [[ 2.0401e-02,  8.1824e-02,  1.8325e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-2.9596e+00, -1.8062e+00, -3.4983e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0859e+00,  1.0521e+00,  1.0215e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 1.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 7.0000e+00,  4.0000e+00,  0.0000e+00,  ..., -1.0000e+00,\n",
       "          -1.0000e+00, -1.0000e+00]]], device='cuda:0'), tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')]\n",
       "y: ScalarCouplingList\n",
       "0,0,0,0,0\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (422550 items)\n",
       "x: ItemList\n",
       "0 4 atoms 3 couplings,1 4 atoms 2 couplings,2 9 atoms 4 couplings,3 9 atoms 3 couplings,4 9 atoms 2 couplings\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti = iter(data.test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192, 9, 29])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(ti)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-1bd2764b029b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mti\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, item, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mItemBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;34m\"Return predicted class, label and probabilities for `item`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrab_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36mone_item\u001b[0;34m(self, item, detach, denorm, cpu)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_ds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSingle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdenorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, ds_type, detach, denorm, cpu)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;34m\"Process and returns items from `DataLoader`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36mpin_memory_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pin_memory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pin_memory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36mpin_memory_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pin_memory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pin_memory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\u001b[0m in \u001b[0;36mpin_memory_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned"
     ]
    }
   ],
   "source": [
    "preds = learner.predict(next(ti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[11.2982,  5.3069,  0.0000, 16.6050,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.0105,  0.9444,  0.0000,  2.9549,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 1.9982,  0.9386,  0.0000,  2.9368,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 4.0000,  0.0000, -1.0000,  5.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]),\n",
       " tensor([[ 18.9033, 195.9123,  15.9771,   4.2330,   2.9117,   8.1336,   4.6962,\n",
       "            6.8533,   2.9176,   5.0508,   6.0641,  15.7475,   4.7835,   5.3321,\n",
       "            3.3230,   5.4686,   4.8848,   3.7132,   5.0865,   5.4959,   7.2669,\n",
       "            5.0019,   3.9938,   4.4293,   3.4651,   2.7777,   5.7563,   6.8418,\n",
       "            4.4474]]),\n",
       " tensor([[ 4.9966, -0.0348,  0.1801],\n",
       "         [ 0.8891, -0.2738, -0.2249],\n",
       "         [ 0.8837,  0.9684,  0.6031]]),\n",
       " tensor([[ 4.9966, -0.0348,  0.1801],\n",
       "         [ 0.8891, -0.2738, -0.2249],\n",
       "         [ 0.8837,  0.9684,  0.6031]])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
