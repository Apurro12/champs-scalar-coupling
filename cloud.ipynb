{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fastai import *\n",
    "from fastai.basic_train import *\n",
    "from fastai.basic_data import *\n",
    "from fastai.data_block import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.train import *\n",
    "from fastai.callback import *\n",
    "from fastai.distributed import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(fname, type_index=None):\n",
    "    t  = pd.read_csv(fname)\n",
    "    s  = pd.read_csv('structures.csv')\n",
    "    \n",
    "    has_y = 'scalar_coupling_constant' in t.columns\n",
    "\n",
    "    if has_y:\n",
    "        # atom-atom level\n",
    "        # molecule_name,atom_index_0,atom_index_1,type,fc,sd,pso,dso\n",
    "        scalar_couplings = pd.read_csv('scalar_coupling_contributions.csv') # fc,sd,pso,dso\n",
    "\n",
    "        # atom level\n",
    "        # molecule_name,atom_index,XX,YX,ZX,XY,YY,ZY,XZ,YZ,ZZ\n",
    "        magnetic_shielding = pd.read_csv('magnetic_shielding_tensors.csv')\n",
    "        # molecule_name,atom_index,mulliken_charge\n",
    "        mulliken_charges = pd.read_csv('mulliken_charges.csv')\n",
    "\n",
    "        # molecule level\n",
    "        # molecule_name,X,Y,Z\n",
    "        dipole_moments = pd.read_csv('dipole_moments.csv')\n",
    "        # molecule_name,potential_energy\n",
    "        potential_energy = pd.read_csv('potential_energy.csv')\n",
    "\n",
    "    t['molecule_index'] = pd.factorize(t['molecule_name'])[0] + t['id'].min()\n",
    "    # make sure we use the same indexes in train/test (test needs to provide type_index)\n",
    "    if type_index is not None:\n",
    "        t['type_index'] = pd.factorize(pd.concat([pd.Series(type_index),t['type']]))[0][len(type_index):]\n",
    "    else:\n",
    "        t['type_index'] = pd.factorize(t['type'])[0]\n",
    "    s = pd.concat([s,pd.get_dummies(s['atom'])], axis=1)\n",
    "\n",
    "    max_items = 785836 if has_y else 422550\n",
    "    max_atoms = int(s.atom_index.max() + 1)\n",
    "\n",
    "    if has_y:\n",
    "        contributions = ['fc','sd','pso','dso']\n",
    "        magnetic_tensors = ['XX','YX','ZX','XY','YY','ZY','XZ','YZ','ZZ']\n",
    "        XYZ = ['X','Y','Z']\n",
    "    xyz = ['x', 'y', 'z']\n",
    "    a_hot = ['C','F','H','N','O']\n",
    "    \n",
    "    x_xyz   = np.zeros((max_items,len(xyz),  max_atoms), dtype=np.float32)\n",
    "    x_a_hot = np.zeros((max_items,len(a_hot),max_atoms), dtype=np.float32)\n",
    "    x_type  = np.zeros((max_items,1,         max_atoms), dtype=np.float32)\n",
    "\n",
    "    if has_y:\n",
    "        y_scalar   = np.zeros((max_items,len(contributions)   ,max_atoms), dtype=np.float32)\n",
    "        y_magnetic = np.zeros((max_items,len(magnetic_tensors),max_atoms), dtype=np.float32)\n",
    "        y_mulliken = np.zeros((max_items,1                    ,max_atoms), dtype=np.float32)\n",
    "\n",
    "        y_dipole   = np.zeros((max_items,len(XYZ)), dtype=np.float32)\n",
    "        y_potential= np.zeros((max_items,1              ), dtype=np.float32)\n",
    "\n",
    "        y_magnetic[...] = np.nan\n",
    "        y_mulliken[...] = np.nan\n",
    "    else:\n",
    "        xt_ids = np.zeros((max_items, max_atoms), dtype=np.int32)\n",
    "\n",
    "\n",
    "    m = np.zeros((max_items,), dtype=np.int32)\n",
    "    i = j = 0\n",
    "    \n",
    "    for (m_name, m_index) ,m_group in tqdm(t.groupby(['molecule_name', 'molecule_index'])):\n",
    "        ss = s[s.molecule_name==m_name]\n",
    "        n_atoms = len(ss)\n",
    "        if has_y:\n",
    "            magnetic = magnetic_shielding[\n",
    "                    (magnetic_shielding['molecule_name']==m_name)][magnetic_tensors].values.T\n",
    "\n",
    "            mulliken = mulliken_charges[\n",
    "                    (mulliken_charges['molecule_name']==m_name)]['mulliken_charge'].values.T\n",
    "\n",
    "            scs = scalar_couplings[scalar_couplings['molecule_name']==m_name]\n",
    "            \n",
    "            y_dipole[j,:]= dipole_moments[dipole_moments['molecule_name']==m_name][XYZ].values\n",
    "            y_potential[j,:]=potential_energy[\n",
    "                potential_energy['molecule_name']==m_name]['potential_energy'].values\n",
    "        \n",
    "        for a_name,a_group in m_group.groupby('atom_index_0'):\n",
    "            \n",
    "            ref_a = ss[ss['atom_index']==a_name]\n",
    "            \n",
    "            x_xyz[i] = 0.\n",
    "            x_a_hot[i] = ref_a[a_hot].values.T\n",
    "            x_type[i] = -1\n",
    "\n",
    "            x_xyz[i,:,:n_atoms] = (ss[xyz].values-ref_a[xyz].values).T  # xyz \n",
    "            x_a_hot[i,:,:n_atoms] = ss[a_hot].T                  # a_hot\n",
    "            x_type[i,0,a_group['atom_index_1']] = a_group['type_index']  # type \n",
    "            \n",
    "            if has_y:\n",
    "                y_scalar[i,:,a_group['atom_index_1']] = scs[scs['atom_index_0']==a_name][contributions]\n",
    "                y_magnetic[i,:,:n_atoms] = magnetic\n",
    "                y_mulliken[i,:,:n_atoms] = mulliken\n",
    "            else:\n",
    "                xt_ids[i,a_group['atom_index_1']] = a_group['id']  \n",
    "\n",
    "            m[i] = m_index\n",
    "            i+=1\n",
    "        j += 1\n",
    "    assert i == max_items\n",
    "    print(i,max_items)\n",
    "    if has_y:\n",
    "        return x_xyz,x_a_hot,x_type, m , y_scalar, y_magnetic, y_mulliken, y_dipole, y_potential\n",
    "    else:\n",
    "        return x_xyz,x_a_hot,x_type, m, xt_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fname = Path('train.npz')\n",
    "try:\n",
    "    npzfile = np.load(train_fname)\n",
    "    x_xyz = npzfile['x_xyz']\n",
    "    x_a_hot = npzfile['x_a_hot']\n",
    "    x_type = npzfile['x_type']\n",
    "    y_scalar = npzfile['y_scalar']\n",
    "    y_magnetic = npzfile['y_magnetic']\n",
    "    y_mulliken = npzfile['y_mulliken']\n",
    "    y_dipole = npzfile['y_dipole']\n",
    "    y_potential = npzfile['y_potential']\n",
    "    m = npzfile['m']\n",
    "    max_items, max_atoms = x_xyz.shape[0], x_xyz.shape[-1]\n",
    "except:\n",
    "    x_xyz,x_a_hot,x_type, m , y_scalar, y_magnetic, y_mulliken, y_dipole, y_potential = \\\n",
    "        preprocess(train_fname.with_suffix('.csv'))\n",
    "    np.savez(train_fname, \n",
    "             x_xyz=x_xyz,\n",
    "             x_a_hot=x_a_hot,\n",
    "             x_type=x_type,\n",
    "             y_scalar=y_scalar,\n",
    "             y_magnetic=y_magnetic,\n",
    "             y_mulliken=y_mulliken,\n",
    "             y_dipole=y_dipole,\n",
    "             y_potential=y_potential,\n",
    "             m=m)\n",
    "n_types = int(x_type[~np.isnan(x_type)].max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fname = Path('test.npz')\n",
    "try:\n",
    "    npzfile = np.load(test_fname)\n",
    "    xt_xyz = npzfile['x_xyz']\n",
    "    xt_a_hot = npzfile['x_a_hot']\n",
    "    xt_type = npzfile['x_type']\n",
    "    mt = npzfile['m']\n",
    "    xt_ids = npzfile['x_ids']\n",
    "except:\n",
    "    train_csv = pd.read_csv(train_fname.with_suffix('.csv'))\n",
    "    xt_xyz,xt_a_hot,xt_type,mt,xt_ids = \\\n",
    "        preprocess(test_fname.with_suffix('.csv'), type_index = pd.factorize(train_csv['type'])[1])\n",
    "    np.savez(test_fname, \n",
    "             x_xyz=xt_xyz,\n",
    "             x_a_hot=xt_a_hot,\n",
    "             x_type=xt_type,\n",
    "             m=mt,\n",
    "             x_ids=xt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(785836, 3, 29),\n",
       " (785836, 5, 29),\n",
       " (785836, 1, 29),\n",
       " (785836, 4, 29),\n",
       " (785836, 9, 29),\n",
       " (785836, 1, 29),\n",
       " (785836, 3),\n",
       " (785836, 1),\n",
       " (785836,)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.shape for v in [x_xyz,x_a_hot,x_type, y_scalar, y_magnetic, y_mulliken, y_dipole, y_potential, m]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(422550, 3, 29), (422550, 5, 29), (422550, 1, 29), (422550,)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.shape for v in [xt_xyz,xt_a_hot,xt_type, mt]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/fxia22/pointnet.pytorch/blob/master/pointnet/model.py\n",
    "class STN3d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STN3d, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 9)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.array([1,0,0,0,1,0,0,0,1]).astype(np.float32))).view(1,9).repeat(batchsize,1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, 3, 3)\n",
    "        return x\n",
    "\n",
    "\n",
    "class STNkd(nn.Module):\n",
    "    def __init__(self, k=64):\n",
    "        super(STNkd, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k*k)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))).view(1,self.k*self.k).repeat(batchsize,1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, self.k, self.k)\n",
    "        return x\n",
    "\n",
    "class PointNetfeat(nn.Module):\n",
    "    def __init__(self, global_feat = True, feature_transform = False):\n",
    "        super(PointNetfeat, self).__init__()\n",
    "        self.stn = STNkd(k=3)\n",
    "        self.conv1 = torch.nn.Conv1d(9, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.global_feat = global_feat\n",
    "        self.feature_transform = feature_transform\n",
    "        if self.feature_transform:\n",
    "            self.fstn = STNkd(k=64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n_pts = x.size()[2]\n",
    "        trans = self.stn(x[:,:3,...].clone())\n",
    "        x = x.transpose(2, 1)\n",
    "        #x = torch.bmm(x, trans)\n",
    "        x[:,:,:3] = torch.bmm(x[:,:,:3].clone(), trans)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        if self.feature_transform:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = x.transpose(2,1)\n",
    "            x = torch.bmm(x, trans_feat)\n",
    "            x = x.transpose(2,1)\n",
    "        else:\n",
    "            trans_feat = None\n",
    "\n",
    "        pointfeat = x\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "        if self.global_feat:\n",
    "            return x, trans, trans_feat\n",
    "        else:\n",
    "            x = x.view(-1, 1024, 1).repeat(1, 1, n_pts)\n",
    "            return torch.cat([x, pointfeat], 1), trans, trans_feat\n",
    "\n",
    "class PointNetCls(nn.Module):\n",
    "    def __init__(self, k=2, feature_transform=False):\n",
    "        super(PointNetCls, self).__init__()\n",
    "        self.feature_transform = feature_transform\n",
    "        self.feat = PointNetfeat(global_feat=True, feature_transform=feature_transform)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.dropout(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1), trans, trans_feat\n",
    "\n",
    "\n",
    "class PointNetDenseCls(nn.Module):\n",
    "    def __init__(self, k = 2, feature_transform=False):\n",
    "        super(PointNetDenseCls, self).__init__()\n",
    "        self.k = k\n",
    "        self.feature_transform=feature_transform\n",
    "        self.feat = PointNetfeat(global_feat=False, feature_transform=feature_transform)\n",
    "        self.conv1 = torch.nn.Conv1d(1088, 512, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(512, 256, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(256, 128, 1)\n",
    "        self.conv4 = torch.nn.Conv1d(128, self.k, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        n_pts = x.size()[2]\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.conv4(x)\n",
    "        x = x.transpose(2,1).contiguous()\n",
    "        x = F.log_softmax(x.view(-1,self.k), dim=-1)\n",
    "        x = x.view(batchsize, n_pts, self.k)\n",
    "        return x, trans, trans_feat\n",
    "    \n",
    "class PointNetDenseReg(nn.Module):\n",
    "    def __init__(self, k = 2, feature_transform=False):\n",
    "        super(PointNetDenseReg, self).__init__()\n",
    "        self.k = k\n",
    "        self.feature_transform=feature_transform\n",
    "        self.feat = PointNetfeat(global_feat=False, feature_transform=feature_transform)\n",
    "        self.conv1 = torch.nn.Conv1d(1088, 512, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(512, 256, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(256, 128, 1)\n",
    "        self.conv4 = torch.nn.Conv1d(128, self.k, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        n_pts = x.size()[2]\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.conv4(x)\n",
    "        #x = x.transpose(2,1).contiguous()\n",
    "        #x = x.view(batchsize, n_pts, self.k)\n",
    "        return x, trans, trans_feat\n",
    "\n",
    "def feature_transform_regularizer(trans):\n",
    "    d = trans.size()[1]\n",
    "    batchsize = trans.size()[0]\n",
    "    I = torch.eye(d)[None, :, :]\n",
    "    if trans.is_cuda:\n",
    "        I = I.cuda()\n",
    "    loss = torch.mean(torch.norm(torch.bmm(trans, trans.transpose(2,1)) - I, dim=(1,2)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeItem(ItemBase):\n",
    "    def __init__(self,i,xyz,a_hot,type): \n",
    "        self.i, self.xyz,self.a_ahot,self.type = i,xyz,a_hot,type\n",
    "        self.data = torch.cat([Tensor(xyz), Tensor(self.a_ahot),Tensor(self.type)], dim=0)\n",
    "    def __str__(self):\n",
    "        n_atoms = np.count_nonzero(np.sum(np.absolute(self.xyz), axis=0))+1\n",
    "        n_couplings = np.sum((x_type[0]!=-1))\n",
    "        return f'{self.i} {n_atoms} atoms {n_couplings} couplings'\n",
    "    \n",
    "class ScalarCouplingItem(ItemBase):\n",
    "    def __init__(self,scalar,magnetic,mulliken,dipole,potential,**kwargs): \n",
    "        self.scalar,self.magnetic,self.mulliken,self.dipole,self.potential = \\\n",
    "            scalar,magnetic,mulliken,dipole,potential\n",
    "        self.data = Tensor(np.sum(scalar, axis=0))\n",
    "    def __str__(self):\n",
    "        res, spacer = '', ''\n",
    "        for s in self.data:\n",
    "            if s==0.: spacer = ' * '\n",
    "            else: \n",
    "                res +=f'{spacer}{s}'\n",
    "                spacer = ' '\n",
    "        return res\n",
    "    def __hash__(self): return hash(str(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMAEMaskedLoss(input_output,target):\n",
    "    input, output = input_output\n",
    "    loss = 0.\n",
    "    n = 0\n",
    "    for type in range(n_types):\n",
    "        mask = (input[:,8,:] == type)\n",
    "        if mask.sum() > 0:\n",
    "            _output,_target = output[:,0,:], target\n",
    "            loss += torch.log((_output[mask] - _target[mask]).abs().mean()+1e-9)\n",
    "            n+=1\n",
    "    return loss/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScalarCouplingList(ItemList):\n",
    "    def __init__(self, items:Iterator, **kwargs):\n",
    "        super().__init__(items, **kwargs)\n",
    "        self.c = 1\n",
    "        self.loss_func = LMAEMaskedLoss\n",
    "\n",
    "    def get(self, i):\n",
    "        o = super().get(i)\n",
    "        return ScalarCouplingItem(*o)\n",
    "\n",
    "    def reconstruct(self,t): return 0; # TODO for viz !!!! ScalarCouplingItem(t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ItemList(items=(MoleculeItem(i,*v) for i,v in enumerate(zip(x_xyz,x_a_hot,x_type))),\n",
    "                label_cls=ScalarCouplingItem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "_, idx_valid_split = train_test_split(range(m.max()+1), test_size=0.1, random_state=13)\n",
    "idx_valid_split = np.argwhere(np.isin(m, idx_valid_split)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.split_by_idx(idx_valid_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ItemLists;\n",
       "\n",
       "Train: ItemList (707619 items)\n",
       "0 5 atoms 4 couplings,1 5 atoms 4 couplings,2 5 atoms 4 couplings,3 5 atoms 4 couplings,4 4 atoms 4 couplings\n",
       "Path: .;\n",
       "\n",
       "Valid: ItemList (78217 items)\n",
       "9 8 atoms 4 couplings,10 8 atoms 4 couplings,11 8 atoms 4 couplings,12 8 atoms 4 couplings,13 8 atoms 4 couplings\n",
       "Path: .;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.label_from_func(\n",
    "    func=lambda o: (y_scalar[o.i], y_magnetic[o.i], y_mulliken[o.i], y_dipole[o.i], y_potential[o.i]),\n",
    "    label_cls=ScalarCouplingList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelLists;\n",
       "\n",
       "Train: LabelList (707619 items)\n",
       "x: ItemList\n",
       "0 5 atoms 4 couplings,1 5 atoms 4 couplings,2 5 atoms 4 couplings,3 5 atoms 4 couplings,4 4 atoms 4 couplings\n",
       "y: ScalarCouplingList\n",
       "84.80760955810547 * -11.256933212280273 -11.254905700683594 -11.25434684753418,84.80741119384766 * -11.254158020019531 -11.254796981811523,84.8093032836914 * -11.254326820373535,84.80950164794922,32.68882751464844 * -11.186695098876953 -11.175664901733398\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (78217 items)\n",
       "x: ItemList\n",
       "9 8 atoms 4 couplings,10 8 atoms 4 couplings,11 8 atoms 4 couplings,12 8 atoms 4 couplings,13 8 atoms 4 couplings\n",
       "y: ScalarCouplingList\n",
       "83.54298400878906 -2.3783071041107178 * -11.700429916381836 -11.697890281677246 3.2528059482574463 13.691265106201172 3.25205397605896,83.54167938232422 -2.378622055053711 * -11.699590682983398 13.692376136779785 3.252530813217163 3.2527239322662354,83.54840850830078 -2.3771567344665527 * 3.2524261474609375 3.2524209022521973 13.692103385925293,-2.3787622451782227 83.54176330566406 * -11.700429916381836 -11.69931411743164,-2.3785178661346436 83.54296875 * -11.697616577148438\n",
       "Path: .;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.databunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = PointNetDenseReg(k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChemCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def on_batch_begin(self,**kwargs):\n",
    "        \"Save the last_input (i.e. current input) for on_loss_begin_callback\"\n",
    "        self.last_input = kwargs['last_input']\n",
    "        \n",
    "    def on_loss_begin(self, last_output:Tuple[Tensor,Tensor,Tensor], **kwargs):\n",
    "        \"Add last_input to last_output, i.e. input to loss function b/c we need it\"\n",
    "        return {'last_output': (self.last_input, last_output[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "learner = Learner(data,net, callbacks=[ChemCallback()], loss_func=LMAEMaskedLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner = learner.to_parallel() I NEED TO FIX .cuda() in pointnet and also fix fp16\n",
    "data.batch_size = 4096*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='200', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.00% [2/200 01:43<2:50:25]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.653413</td>\n",
       "      <td>1.670763</td>\n",
       "      <td>00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.178664</td>\n",
       "      <td>1.222950</td>\n",
       "      <td>00:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [5/10 00:02<00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(200, max_lr=3e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (root)",
   "language": "python",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
