{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T19:07:15.891480Z",
     "start_time": "2019-08-26T19:07:15.271666Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import gc\n",
    "from fastai.core import parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T19:07:16.572491Z",
     "start_time": "2019-08-26T19:07:16.566801Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subs = [\n",
    "    'loss-5.7552val-2.9950', 'loss-4.9516val-3.0042', 'loss-5.9943val-2.7766',\n",
    "#    'loss-4.0414val-2.7287', 'loss-4.9044val-2.5880', 'loss-4.9516val-2.8229',\n",
    "    'loss-4.0414val-2.7287', 'loss-4.9516val-2.8229',\n",
    "    'loss-5.6540val-3.0131', 'loss-5.1336val-3.0759', 'loss-5.5435val-3.0776',\n",
    "    'loss-3.5933val-3.0637', 'loss-5.6477val-3.0793',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T19:07:20.186683Z",
     "start_time": "2019-08-26T19:07:18.084161Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x = None\n",
    "for sub in subs:\n",
    "    df = pd.read_csv('%s_val' % sub)\n",
    "    df = df.drop(['id'], axis=1)\n",
    "    if train_x is None:\n",
    "        train_x = df\n",
    "        train_x['scalar_coupling_constant_%s' % sub] = df['scalar_coupling_constant']\n",
    "    else:\n",
    "        train_x['scalar_coupling_constant_%s' % sub] = df['scalar_coupling_constant']\n",
    "train_x = train_x.drop(['scalar_coupling_constant'], axis=1).astype('float32')\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T19:07:44.920210Z",
     "start_time": "2019-08-26T19:07:34.211024Z"
    }
   },
   "outputs": [],
   "source": [
    "test_x = None\n",
    "for sub in subs:\n",
    "    df = pd.read_csv('%s' % sub)\n",
    "    df = df.drop(['id'], axis=1)\n",
    "    if test_x is None:\n",
    "        test_x = df\n",
    "        test_x['scalar_coupling_constant_%s' % sub] = df['scalar_coupling_constant']\n",
    "    else:\n",
    "        test_x['scalar_coupling_constant_%s' % sub] = df['scalar_coupling_constant']\n",
    "test_x = test_x.drop(['scalar_coupling_constant'], axis=1).astype('float32')\n",
    "test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T19:07:45.924754Z",
     "start_time": "2019-08-26T19:07:44.922305Z"
    }
   },
   "outputs": [],
   "source": [
    "test_y = pd.read_csv('temp_-3.225.csv')\n",
    "test_y = test_y.drop(['id'], axis=1)['scalar_coupling_constant'].astype('float32')\n",
    "test_y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T19:07:48.502220Z",
     "start_time": "2019-08-26T19:07:45.927108Z"
    }
   },
   "outputs": [],
   "source": [
    "type_index = {\n",
    "    '1JHC': 0,\n",
    "    '2JHH': 1,\n",
    "    '1JHN': 2,\n",
    "    '2JHN': 3,\n",
    "    '2JHC': 4,\n",
    "    '3JHH': 5,\n",
    "    '3JHC': 6,\n",
    "    '3JHN': 7\n",
    "}\n",
    "test_types = pd.read_csv('test.csv')['type']\n",
    "test_types_idx = []\n",
    "for value in test_types.values:\n",
    "    test_types_idx.append(type_index[value])\n",
    "test_types_idx = np.array(test_types_idx)\n",
    "test_types_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T19:07:48.706605Z",
     "start_time": "2019-08-26T19:07:48.504346Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv('validation_targets')\n",
    "train_y = train_y.drop(['id'], axis=1)['scalar_coupling_constant'].astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T19:07:48.817918Z",
     "start_time": "2019-08-26T19:07:48.708700Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types = pd.read_csv('validation_types')\n",
    "types = types.drop(['id'], axis=1)['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T19:07:55.440871Z",
     "start_time": "2019-08-26T19:07:55.434951Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T19:07:58.330897Z",
     "start_time": "2019-08-26T19:07:58.319238Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "\n",
    "reg1 = KNeighborsRegressor(n_neighbors=20) # -3.19\n",
    "reg2 = LinearRegression() # -3.16\n",
    "reg3 = LinearRegression(fit_intercept=False) \n",
    "reg4 = RANSACRegressor() #-3.177\n",
    "reg5 = TheilSenRegressor() #-3.177\n",
    "#reg6 = RandomForestRegressor(n_estimators=10) #-4.04\n",
    "#reg6 = BayesianRidge() # -3.16867\n",
    "#reg6 = HuberRegressor() # -3.1839\n",
    "\n",
    "#model = VotingRegressor(estimators=[('knr', reg1), ('lr', reg2), ('lr2', reg3), ('ransac', reg4), ('th', reg5)])\n",
    "model = VotingRegressor(estimators=[\n",
    "    ('knr', reg1), ('lr2', reg2), ('ransac', reg4), ('th', reg5)],n_jobs=-1)\n",
    "#model = VotingRegressor(estimators=[('hb', reg6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T19:07:59.958238Z",
     "start_time": "2019-08-26T19:07:59.953513Z"
    }
   },
   "outputs": [],
   "source": [
    "y = train_y\n",
    "X = train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T19:08:01.262366Z",
     "start_time": "2019-08-26T19:08:01.249924Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_lmae(gt, pred, types):\n",
    "    types = types.values.astype(np.int)\n",
    "    gt = np.asarray(gt)\n",
    "    pred = np.asarray(pred)    \n",
    "    loss = 0.\n",
    "    for type in np.unique(types):\n",
    "        mask = types == type\n",
    "        loss += np.log(np.mean(np.abs(gt[mask]-pred[mask])))\n",
    "    loss = loss / len(np.unique(types))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV\n",
    "# https://www.kaggle.com/aharless/simple-catboost-cv-lb-281\n",
    "OPTIMIZE_ROUNDS = False\n",
    "y_test_pred = None\n",
    "y_test_pred = [None, None, None, None, None, None, None, None]\n",
    "\n",
    "K = 1\n",
    "\n",
    "def calc_type(type, iii):\n",
    "    loss = 0\n",
    "    y_test_pred = None\n",
    "    for i, (train_index, test_index) in enumerate([(range(len(X)),\n",
    "                                                    range(len(y)))]):\n",
    "        gc.collect()\n",
    "\n",
    "        # Create data for this fold\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "        X_train, X_valid = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "        type_train, type_valid = types.iloc[train_index], types.iloc[\n",
    "            test_index]\n",
    "\n",
    "        y_train, y_valid, X_train, X_valid, type_train, type_valid = y_train[\n",
    "            type_train == type], y_valid[type_valid == type], X_train[\n",
    "                type_train == type], X_valid[type_valid == type], type_train[\n",
    "                    type_train == type], type_valid[type_valid == type]\n",
    "\n",
    "        fit_model = model.fit(\n",
    "            np.concatenate([X_train, test_x[test_types_idx == type][:X_train.shape[0]]],\n",
    "                           axis=0),\n",
    "            np.concatenate([y_train, test_y[test_types_idx == type][:y_train.shape[0]]],axis=0))\n",
    "\n",
    "        # Generate validation predictions for this fold\n",
    "        pred = fit_model.predict(X_valid)\n",
    "        loss += eval_lmae(y_valid, pred, type_valid)\n",
    "\n",
    "        # Accumulate test set predictions\n",
    "        if y_test_pred is None:\n",
    "            y_test_pred  = fit_model.predict(test_x)\n",
    "        else:\n",
    "            y_test_pred += fit_model.predict(test_x)\n",
    "        return (type, y_test_pred, loss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = parallel(calc_type, range(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred, loss = [None] * 8, [None] * 8\n",
    "for (type,y_test_preds,type_loss) in res:\n",
    "    y_test_pred[type] = y_test_preds\n",
    "    loss[type] = type_loss\n",
    "for i in range(8):\n",
    "    print(f\"Type {i} LMAE: {loss[i]}\")\n",
    "print(f\"\\nFinal  LMAE: {np.mean(loss)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T08:33:55.350492Z",
     "start_time": "2019-08-23T08:33:52.954231Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred_list = y_test_pred\n",
    "y_test_pred = []\n",
    "\n",
    "for idx, type_idx in enumerate(test_types_idx):\n",
    "    y_test_pred.append(y_test_pred_list[type_idx][idx])\n",
    "y_test_pred = np.array(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T08:33:55.357613Z",
     "start_time": "2019-08-23T08:33:55.353259Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T08:33:56.325635Z",
     "start_time": "2019-08-23T08:33:55.359559Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('%s' % subs[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T08:33:56.339411Z",
     "start_time": "2019-08-23T08:33:56.327613Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['scalar_coupling_constant'] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T08:33:56.349113Z",
     "start_time": "2019-08-23T08:33:56.341358Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T08:34:01.668174Z",
     "start_time": "2019-08-23T08:34:01.660488Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_fname = 'LMAE_' + str(loss) + '-LinearRegressionByType-1fold'\n",
    "sub_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T08:34:19.267845Z",
     "start_time": "2019-08-23T08:34:07.078474Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(sub_fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T08:34:19.274832Z",
     "start_time": "2019-08-23T08:34:19.270243Z"
    }
   },
   "outputs": [],
   "source": [
    "comp = 'champs-scalar-coupling'\n",
    "m = ' '.join(subs) + ' estimators: ' + ' '.join([name for name,_ in model.estimators])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T08:08:09.278559Z",
     "start_time": "2019-08-23T08:08:03.356723Z"
    }
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c {comp} -f {sub_fname} -m '{m}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T08:09:12.271724Z",
     "start_time": "2019-08-23T08:08:11.482797Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(60)\n",
    "!kaggle competitions submissions -c {comp} -v > submissions-{comp}.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T08:09:12.292451Z",
     "start_time": "2019-08-23T08:09:12.277197Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submissions = pd.read_csv(f'submissions-{comp}.csv')\n",
    "submissions.iloc[0].publicScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (root)",
   "language": "python",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
